{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "    \n",
    "1. first get the webpage https://www.naukri.com/\n",
    "    \n",
    "2. Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "\n",
    "3. Then click the search button.\n",
    "\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "\n",
    "Note- All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets now import all the required Libraries \n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 93.0.4577\n",
      "Get LATEST driver version for 93.0.4577\n",
      "Driver [C:\\Users\\Sourabh\\.wdm\\drivers\\chromedriver\\win32\\93.0.4577.63\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "from webdriver_manager.chrome import ChromeDriverManager \n",
    "driver= webdriver.Chrome(ChromeDriverManager().install())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Sourabh\\Downloads\\chromedriver_win32 (1)\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_job = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_job\n",
    "\n",
    "search_job.send_keys('Data Analyst')\n",
    "\n",
    "Search_job = driver.find_element_by_xpath('//input[@class=\"sugInp\"]')\n",
    "Search_job\n",
    "\n",
    "#finding element for job location bar\n",
    "search_loc = driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "search_loc.send_keys(\"Bangalore\")\n",
    "\n",
    "#Do click using xpath function\n",
    "search_btn = driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn\n",
    "\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"5b803cd8-45df-437f-9d90-2bcc518a6034\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"e1554a9c-e04e-4730-a40f-444b98e8de75\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"8e22c3d3-07e8-4bc9-914d-204b112ef2f5\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"96c6301d-dc2f-46cb-a3f6-6c07a595b446\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"1dde0a91-2be7-4b75-b824-627ca8f97966\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"2289589a-4cc4-43a4-a102-e9114f7c8a96\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"8f8a7025-d22d-420b-822b-4dac47e56596\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"7be312f7-2918-497e-9344-7c66cd53d09f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"6edefe40-2660-48d3-85cf-6119ebbc27bf\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"e875cb19-11d3-46d4-a185-581d088b9172\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"dca40cd4-5219-4e21-892d-60a4f7462d7e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"cf28d5ec-fb2d-44c9-8869-b4f0544eed24\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"37148e53-c7b0-4d61-b218-bfed6cadd4fb\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"dae42159-5ffe-43b4-8c72-6ffa1a337a7a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"78b161d3-c58d-4669-b1b2-894e5434bde7\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"7a02476e-ed25-400a-89a3-042425a55479\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"b4bec7ec-d0b9-417d-98d2-c91d31d969f5\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"35b97547-88ca-4695-9205-cbcbc9c8682d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"a39bff08-8bcb-4a05-a961-dc624154d710\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"86577be4-2024-47ac-96a1-85e842cfa0a5\")>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#So lets extract all the tags having the job-titles\n",
    "titles_tags = driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "titles_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will extract the text from these tags one by one by looping over these tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Senior Data Analyst',\n",
       " 'Tcs Hiring For Senior Data Analyst (bfsi domain)',\n",
       " 'Business Data Analyst',\n",
       " 'Business Data Analyst',\n",
       " 'Business Data Analyst - Google Data Studio & SQL',\n",
       " 'Senior Data Analyst',\n",
       " 'Tcs Hiring For MDM (master data management) Data Analyst (bfsi domain)',\n",
       " 'Senior Data Analyst IDAM Services',\n",
       " 'Data Analyst/Sr.Data Engineer',\n",
       " 'SENIOR DATA ANALYST',\n",
       " 'Executive Data Analyst',\n",
       " 'Senior Data Analyst IN4',\n",
       " 'Analyst & Designer - Software - Data Analysis',\n",
       " 'Data Analyst - I/II',\n",
       " 'Systems and Data Analyst, Safety and Provisioning',\n",
       " 'Data Analyst',\n",
       " 'Business Data Analyst - MIS & Reporting',\n",
       " 'Sr Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Senior Data Analyst']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_titles= []\n",
    "for i in titles_tags:\n",
    "    job_titles.append(i.text)\n",
    "job_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will extract all the html tags where we have the company names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"76bfb1d2-18f9-4ef4-bd2a-9f44950e352a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"d4d64ecb-5bac-4f00-b362-519e08616e20\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"b25ff821-47ee-4ed3-890d-02d427626ade\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"ce72f01f-2ff0-4a40-b214-274a5b26dc96\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"6e80c9d0-0951-41d0-adc2-364d22db4dbf\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"c9d28267-1a9b-47dd-9e30-af1c23f5637c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"a512542a-70f3-43a7-b8e3-1ca94690c0f9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"34716d05-f2bf-4690-b82a-28854b6d1fa8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"0134a511-3a07-49b9-b129-4bc36e11a3a2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"195b470e-3482-4ba5-8953-47dfa23db5c1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"4b030798-998d-48ef-a910-43f733a3687a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"19bfef4f-5fe7-482f-8961-e5f39b7dd6ad\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"b6b481c7-333b-4c81-af76-0a2385c5cd91\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"748a9a03-694e-4bad-9d60-395ad546a1fe\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"e06bddc8-d7d8-48eb-acc8-daa8e3e976af\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"62b06037-c1b4-47b4-a8bd-0e9a9f56df36\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"272c907c-0d9f-44c3-ab5c-9c6390533388\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"71f4c4c0-74a4-4469-9e75-48e0789cdc33\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"040b673c-3644-4fc6-b9dc-f3b30d5a561a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"8d39a389-21d8-4f6d-a34c-250d0dc1bb6d\")>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies_tags= driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "companies_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gaussian Networks Private Limited',\n",
       " 'Tata Consultancy Services Ltd.',\n",
       " 'Trigent Software',\n",
       " 'Trigent Software',\n",
       " 'AVE-Promagne',\n",
       " 'Virtusa Consulting Services Pvt Ltd',\n",
       " 'Tata Consultancy Services Ltd.',\n",
       " 'GlaxoSmithKline Pharmaceuticals Limited',\n",
       " 'SYREN TECHNOLOGIES PRIVATE LIMITED',\n",
       " 'McAfee Software (India) Pvt. Ltd',\n",
       " 'Gokaldas Exports Ltd',\n",
       " 'Walmart Labs',\n",
       " 'HyreFox Consultants Pvt Ltd',\n",
       " 'Philips India Limited',\n",
       " 'AECOM India Private Limited',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'INTERTRUST GROUP',\n",
       " 'Empower Retirement',\n",
       " 'Flipkart',\n",
       " 'Flipkart']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_names=[]\n",
    "\n",
    "for i in companies_tags:\n",
    "    company_names.append(i.text)\n",
    "company_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will extract all the html tags where we have the experience required data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"73ee40df-a514-466b-ab0c-082d40d0bff4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"c620e4d8-6844-4aef-8375-f3a73f954dd8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"761c2d7d-2268-4aeb-a07f-83b4111c34fd\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"26a3ee13-f638-4a29-913e-e40118ef4940\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"7d4776d4-d2a5-460a-ba6b-c8618a1250a0\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"a5f161e3-f0cd-4745-82f9-8bcc50223dc2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"b0e4c46b-3321-4b16-bac7-92780d2fdd44\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"7f47e57a-a012-4425-a9d8-7103d2c77328\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"a2d0b0c7-09e1-4aa7-93c5-0e484a3a93f6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"7e6f31e0-3e52-4e33-98c0-87e53ede0c34\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"78148613-0af7-43cf-ada2-2b9b11b2b046\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"4d6018d8-76f4-4023-bd29-3808cc1805c9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"fd894ff7-9056-44cb-a184-54625849f828\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"c1cb2dea-5191-4eee-ab33-48f4be93391a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"215bd0a7-cfff-4758-9ffe-d01b6b93fa03\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"ac709ee0-f574-4cc9-9907-73982a3bcf32\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"c27c1b5c-c81e-4def-8bf6-3355ca83604d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"39cd1fa6-dfe2-4a94-93ce-f50d95bdda75\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"de568ad0-6958-4994-9538-b96e392a6440\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"cac593b1-be98-41a9-8a89-e740d1da2cfc\")>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experience_tags= driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]//span')\n",
    "experience_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3-5 Yrs',\n",
       " '6-11 Yrs',\n",
       " '5-10 Yrs',\n",
       " '5-10 Yrs',\n",
       " '3-8 Yrs',\n",
       " '8-12 Yrs',\n",
       " '6-11 Yrs',\n",
       " '4-8 Yrs',\n",
       " '4-9 Yrs',\n",
       " '6-8 Yrs',\n",
       " '0-3 Yrs',\n",
       " '8-10 Yrs',\n",
       " '5-7 Yrs',\n",
       " '3-6 Yrs',\n",
       " '2-7 Yrs',\n",
       " '1-4 Yrs',\n",
       " '3-8 Yrs',\n",
       " '5-8 Yrs',\n",
       " '2-3 Yrs',\n",
       " '3-8 Yrs']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experience_list=[]\n",
    "\n",
    "for i in experience_tags:\n",
    "    experience_list.append(i.text)\n",
    "experience_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"c09b7f47-d68b-454a-acd7-b43c0902d590\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"c9003adf-4b36-4a1c-8035-4be105ec29ea\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"488ce54f-1c72-40fa-aa51-1f8d66c95d44\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"ecef3955-43ad-4374-8b96-47b9c30a0206\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"bd1a5368-0368-4764-b296-2e02fab1e915\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"6b237f35-f439-445a-9d5c-66514bde84c1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"aaa1c063-2b14-45ad-8833-eb9a9a4d917b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"98b82ff7-d84e-49da-a1aa-18513e4a070f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"7b75751b-4f45-4a22-8ead-9047f6ca10d5\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"6bc55208-253f-41a9-b102-5fa069a4f28a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"a4768d7f-ea65-4718-941d-3c469ce490ce\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"21f77491-5de5-41b8-acde-b9dc5cc57c82\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"9e80b279-d297-40db-a018-cd099b58ed67\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"7b0b77b1-68c0-4e0c-8edf-53e5499722fd\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"e02e3bb5-5ad0-468d-83c6-6a303bb7965f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"d3000272-1e38-497a-b860-1077a310f287\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"8d94dd8e-73f0-4268-9b95-4fc7f00dd8ca\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"d25e5598-36de-4b50-b44b-eae692f77537\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"393c4302-c559-4f89-9411-f9bc046ef885\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a335445fe2f23623c4010fd53c87978e\", element=\"79132a7c-2d36-49c6-98ba-56ba769036b9\")>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_tags= driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span[1]\")\n",
    "location_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Chennai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram, Chennai, Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Chennai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Chennai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bengaluru/Bangalore',\n",
       " 'Mumbai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_list=[]\n",
    "\n",
    "for i in location_tags:\n",
    "    location_list.append(i.text)\n",
    "location_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " lets first check the length of each of the list, to check if the lenght of all of the lists are not equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20\n"
     ]
    }
   ],
   "source": [
    "print(len(job_titles),len(company_names),len(experience_list),len(location_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>experience_required</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Gaussian Networks Private Limited</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tcs Hiring For Senior Data Analyst (bfsi domain)</td>\n",
       "      <td>Tata Consultancy Services Ltd.</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>Trigent Software</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>Trigent Software</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business Data Analyst - Google Data Studio &amp; SQL</td>\n",
       "      <td>AVE-Promagne</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Virtusa Consulting Services Pvt Ltd</td>\n",
       "      <td>8-12 Yrs</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tcs Hiring For MDM (master data management) Da...</td>\n",
       "      <td>Tata Consultancy Services Ltd.</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Analyst IDAM Services</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst/Sr.Data Engineer</td>\n",
       "      <td>SYREN TECHNOLOGIES PRIVATE LIMITED</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Hyderabad/Secunderabad, Chennai, Bangalore/Ben...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SENIOR DATA ANALYST</td>\n",
       "      <td>McAfee Software (India) Pvt. Ltd</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                                Senior Data Analyst   \n",
       "1   Tcs Hiring For Senior Data Analyst (bfsi domain)   \n",
       "2                              Business Data Analyst   \n",
       "3                              Business Data Analyst   \n",
       "4   Business Data Analyst - Google Data Studio & SQL   \n",
       "5                                Senior Data Analyst   \n",
       "6  Tcs Hiring For MDM (master data management) Da...   \n",
       "7                  Senior Data Analyst IDAM Services   \n",
       "8                      Data Analyst/Sr.Data Engineer   \n",
       "9                                SENIOR DATA ANALYST   \n",
       "\n",
       "                                   company experience_required  \\\n",
       "0        Gaussian Networks Private Limited             3-5 Yrs   \n",
       "1           Tata Consultancy Services Ltd.            6-11 Yrs   \n",
       "2                         Trigent Software            5-10 Yrs   \n",
       "3                         Trigent Software            5-10 Yrs   \n",
       "4                             AVE-Promagne             3-8 Yrs   \n",
       "5      Virtusa Consulting Services Pvt Ltd            8-12 Yrs   \n",
       "6           Tata Consultancy Services Ltd.            6-11 Yrs   \n",
       "7  GlaxoSmithKline Pharmaceuticals Limited             4-8 Yrs   \n",
       "8       SYREN TECHNOLOGIES PRIVATE LIMITED             4-9 Yrs   \n",
       "9         McAfee Software (India) Pvt. Ltd             6-8 Yrs   \n",
       "\n",
       "                                            location  \n",
       "0              Gurgaon/Gurugram, Bangalore/Bengaluru  \n",
       "1                       Chennai, Bangalore/Bengaluru  \n",
       "2                                Bangalore/Bengaluru  \n",
       "3                                Bangalore/Bengaluru  \n",
       "4                                Bangalore/Bengaluru  \n",
       "5  Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram...  \n",
       "6                       Chennai, Bangalore/Bengaluru  \n",
       "7                                Bangalore/Bengaluru  \n",
       "8  Hyderabad/Secunderabad, Chennai, Bangalore/Ben...  \n",
       "9                                Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making the dataframe\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['title']=job_titles\n",
    "jobs['company']=company_names\n",
    "jobs['experience_required']=experience_list\n",
    "jobs['location']=location_list\n",
    "\n",
    "jobs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- 1. All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Sourabh\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_job = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_job\n",
    "\n",
    "search_job.send_keys('Data Scientist')\n",
    "\n",
    "Search_job = driver.find_element_by_xpath('//input[@class=\"sugInp\"]')\n",
    "Search_job\n",
    "\n",
    "#finding element for job location bar\n",
    "search_loc = driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "search_loc.send_keys(\"Bangalore\")\n",
    "\n",
    "#Do click using xpath function\n",
    "search_btn = driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn\n",
    "\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"1c0b14b7-22cb-4a4d-b25a-a305bf488abf\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"b81f5929-fcc7-4c32-b451-ddbf37870753\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"c090a175-a593-429e-ba8c-ed2c2e6b450d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"64a93336-720f-4347-80a7-421065412e60\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"774020a3-4483-45c4-8b26-127e85b3817d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"0423459d-f4c9-46c0-a94e-6a8206cd7d9d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"443fab71-ad50-44b6-b97c-735335007ab3\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"7c00a02c-d733-4ad2-9d50-ffb32230d8d9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"4e0d282d-f5cc-4160-8eb7-2cbb420ba941\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"da89f11a-fa69-4b3b-ace6-7f25feb5ac1e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"27fa85b2-e4b5-4c62-be51-67679910e907\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"deb4d1d0-2a2b-4382-b7c1-e0746e2c4970\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"b0786eba-c006-45f6-8c80-898ef44abddc\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"1c10a891-57a9-43ff-ae95-84cb8f424336\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"87c9cef3-9f20-4199-99cb-ec35663175e0\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"d5f056e2-70ae-42ce-abfe-bdeb77a896b6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"3a1a1067-fd92-45f7-aaf1-0d159e170fbb\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"40a02407-0c5b-4f90-bd95-cde21767e874\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"f0f3c0e0-9e22-42ff-8f3d-934200f6c7c9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"00d79eac-1cd8-4fac-b9e0-80dd3e8b0b6c\")>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#So lets extract all the tags having the job-titles\n",
    "titles_tags = driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "titles_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will extract the text from these tags one by one by looping over these tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hiring For Data Scientist',\n",
       " 'Lead Data Scientist BFSI',\n",
       " 'Associate Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist: Advanced Analytics',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Sr Data Scientist',\n",
       " 'Sr Data Scientist',\n",
       " 'SENIOR DATA SCIENTIST',\n",
       " 'Senior Data Scientist IN4',\n",
       " 'Senior Data Scientist (Marketplace)',\n",
       " 'Hiring For Manager and Sr. Manager | Data Scientist',\n",
       " 'Requirement For Data Scientist - Mumbai & Bangalore',\n",
       " 'Data Scientist (Python & SQL)',\n",
       " 'Lead Data Scientist - Machine Learning/ Data Mining',\n",
       " 'Data Scientist- Senior Business Analyst/Lead Analyst',\n",
       " 'Data Scientist- Python/R (3+ Years)',\n",
       " 'Data Scientist - IN3']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_titles= []\n",
    "for i in titles_tags:\n",
    "    job_titles.append(i.text)\n",
    "job_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"5ae2e2f8-e9df-4a65-9ca3-817ee5feea19\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"b79549f6-a2cd-4fd6-8b50-6d928161a27b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"0ef3756f-82d6-4b35-a7f8-dfe23c166b11\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"6f9f7557-9c0e-4963-9139-8ec257faeeb8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"7cf9db63-f044-4ebe-b857-a732f416720c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"13acca08-be9f-4579-b332-eaf06bc2c78d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"9d2cdfd8-fc2f-4061-89c5-dbc7d20dfd37\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"2f7a2cf5-5fe6-4b39-9f05-f5862515ee2a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"c88d70c0-c566-41e3-a85a-3c0daafdcf18\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"b39f4ab4-2429-44c8-a2f2-e9eadb00f0f8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"9f9dac28-017b-4b32-bc1c-3c705d238835\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"9b534dd3-fb89-43d8-8270-f6387928031b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"8729f38e-7b63-4799-9977-469c538cf6ce\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"81114785-47df-40f0-82fe-03cf5db47e3c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"2b22ab5c-27b8-4956-a5a8-b6e64a717a73\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"75f96531-ecf2-463e-af70-c6163ecade16\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"37addd20-c0b3-4e1e-99ac-c6d51c4eff3d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"ed6b29e8-9ed8-4c5d-a2cd-d51a58ca9e51\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"591d5bb1-2017-49d7-ac9c-0f02ba22d233\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"d71f9369-243e-485b-990a-db79fbb8daa9\")>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we will extract all the html tags where we have the company names.\n",
    "companies_tags= driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "companies_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tata Consultancy Services Ltd.',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Philips India Limited',\n",
       " 'Allegis Services India Pvt. Ltd.',\n",
       " 'Allegis Services India Pvt. Ltd.',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Walmart Labs',\n",
       " 'Airbnb',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Happiest Minds Technologies Pvt.Ltd',\n",
       " 'Walmart Labs',\n",
       " 'Walmart Labs',\n",
       " 'Vision Beyond Resources India Private Limited',\n",
       " 'CRISIL LIMITED',\n",
       " 'AVE-Promagne',\n",
       " 'Wrackle Technologies Pvt Ltd',\n",
       " 'Evalueserve.com Pvt. Ltd',\n",
       " 'CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVATE L IMITED',\n",
       " 'Walmart Labs']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_names=[]\n",
    "\n",
    "for i in companies_tags:\n",
    "    company_names.append(i.text)\n",
    "company_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"376cc09d-b8a8-44f4-9ea5-fa965b4048f4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"19f603b3-087d-47b5-b80b-8b77d004e6cb\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"4575ab8b-1549-45dd-864f-16192da2aa3c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"aacb0e15-552f-4cae-b6f7-908c84772d3a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"3b21077e-6ac2-425f-a7f6-7deb5470f0cc\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"173ce705-fdd2-425e-96c9-09d5be3cbf55\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"c2de9365-a37a-4304-b3e2-2ff2f78d40c3\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"e22b351e-9bed-4bcf-b6c6-05852eff1563\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"2d26ee21-d4d6-4ea3-94e8-f74a98ad7c43\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"33d3d79f-6bb5-4a03-ab93-fdc98d686c09\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"aecc1e0a-52f7-432d-874b-3a6638b7624b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"dc791d1a-d1d2-47f6-acc6-fd6ddb540dce\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"862c8b8d-aaa0-4191-86c5-dcf69d5cf32b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"80266a18-2123-4ff8-81bf-360c8f784a00\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"f3df7982-0bc3-42c6-9f37-76610f1f8011\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"21d0d536-9f0b-44c2-b52d-8152d5285adf\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"acf4f646-1cb0-415c-aa8c-59b436b05d08\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"3c08c1a6-f133-4401-a4e3-838dd4bfc1c1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"fe1dc1ba-2dfd-4720-b2a7-f2a0d88a8b0e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"c553085c-aa73-4d0c-858d-a04143322985\")>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_tags= driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span[1]\")\n",
    "location_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chennai, Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Bengaluru/Bangalore',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bengaluru/Bangalore',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bengaluru/Bangalore',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Noida, Mumbai, New Delhi, Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Hyderabad/Secunderabad, Chennai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_list=[]\n",
    "\n",
    "for i in location_tags:\n",
    "    location_list.append(i.text)\n",
    "location_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to scrape full job description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"1c0b14b7-22cb-4a4d-b25a-a305bf488abf\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"b81f5929-fcc7-4c32-b451-ddbf37870753\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"c090a175-a593-429e-ba8c-ed2c2e6b450d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"64a93336-720f-4347-80a7-421065412e60\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"774020a3-4483-45c4-8b26-127e85b3817d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"0423459d-f4c9-46c0-a94e-6a8206cd7d9d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"443fab71-ad50-44b6-b97c-735335007ab3\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"7c00a02c-d733-4ad2-9d50-ffb32230d8d9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"4e0d282d-f5cc-4160-8eb7-2cbb420ba941\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"da89f11a-fa69-4b3b-ace6-7f25feb5ac1e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"27fa85b2-e4b5-4c62-be51-67679910e907\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"deb4d1d0-2a2b-4382-b7c1-e0746e2c4970\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"b0786eba-c006-45f6-8c80-898ef44abddc\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"1c10a891-57a9-43ff-ae95-84cb8f424336\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"87c9cef3-9f20-4199-99cb-ec35663175e0\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"d5f056e2-70ae-42ce-abfe-bdeb77a896b6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"3a1a1067-fd92-45f7-aaf1-0d159e170fbb\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"40a02407-0c5b-4f90-bd95-cde21767e874\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"f0f3c0e0-9e22-42ff-8f3d-934200f6c7c9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b3f859bb4cb9c88696778bf5aafbfac1\", element=\"00d79eac-1cd8-4fac-b9e0-80dd3e8b0b6c\")>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descp_tags = driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "\n",
    "descp_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.naukri.com/job-listings-hiring-for-data-scientist-tata-consultancy-services-chennai-bangalore-bengaluru-mumbai-all-areas-3-to-8-years-110921000464?src=jobsearchDesk&sid=16315318701047674&xp=1&px=1',\n",
       " 'https://www.naukri.com/job-listings-lead-data-scientist-bfsi-ibm-india-pvt-limited-bengaluru-bangalore-5-to-9-years-070921901691?src=jobsearchDesk&sid=16315318701047674&xp=2&px=1',\n",
       " 'https://www.naukri.com/job-listings-associate-data-scientist-philips-india-limited-bangalore-bengaluru-3-to-5-years-060921501985?src=jobsearchDesk&sid=16315318701047674&xp=3&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-allegis-services-india-pvt-ltd-bangalore-bengaluru-4-to-8-years-130921603395?src=jobsearchDesk&sid=16315318701047674&xp=4&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-allegis-services-india-pvt-ltd-bangalore-bengaluru-4-to-8-years-130921003393?src=jobsearchDesk&sid=16315318701047674&xp=5&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-advanced-analytics-ibm-india-pvt-limited-bengaluru-bangalore-3-to-7-years-070921901677?src=jobsearchDesk&sid=16315318701047674&xp=6&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-walmart-labs-bangalore-bengaluru-6-to-10-years-090921501063?src=jobsearchDesk&sid=16315318701047674&xp=7&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-airbnb-bangalore-bengaluru-7-to-12-years-080921500017?src=jobsearchDesk&sid=16315318701047674&xp=8&px=1',\n",
       " 'https://www.naukri.com/job-listings-sr-data-scientist-ibm-india-pvt-limited-bengaluru-bangalore-6-to-8-years-010921906637?src=jobsearchDesk&sid=16315318701047674&xp=9&px=1',\n",
       " 'https://www.naukri.com/job-listings-sr-data-scientist-ibm-india-pvt-limited-bangalore-bengaluru-6-to-8-years-010921906105?src=jobsearchDesk&sid=16315318701047674&xp=10&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-happiest-minds-technologies-pvt-ltd-bangalore-bengaluru-5-to-10-years-070921501517?src=jobsearchDesk&sid=16315318701047674&xp=11&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-in4-walmart-labs-bangalore-bengaluru-7-to-10-years-090921501064?src=jobsearchDesk&sid=16315318701047674&xp=12&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-marketplace-walmart-labs-bangalore-bengaluru-4-to-8-years-090921500549?src=jobsearchDesk&sid=16315318701047674&xp=13&px=1',\n",
       " 'https://www.naukri.com/job-listings-hiring-for-manager-and-sr-manager-data-scientist-vision-beyond-resources-india-private-limited-noida-mumbai-new-delhi-gurgaon-gurugram-bangalore-bengaluru-8-to-13-years-090921005986?src=jobsearchDesk&sid=16315318701047674&xp=14&px=1',\n",
       " 'https://www.naukri.com/job-listings-requirement-for-data-scientist-mumbai-bangalore-crisil-limited-bangalore-bengaluru-mumbai-all-areas-2-to-6-years-080921005523?src=jobsearchDesk&sid=16315318701047674&xp=15&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-python-sql-ave-promagne-hyderabad-secunderabad-chennai-bangalore-bengaluru-6-to-8-years-060921904967?src=jobsearchDesk&sid=16315318701047674&xp=16&px=1',\n",
       " 'https://www.naukri.com/job-listings-lead-data-scientist-machine-learning-data-mining-wrackle-technologies-pvt-ltd-bangalore-bengaluru-6-to-11-years-080221900886?src=jobsearchDesk&sid=16315318701047674&xp=17&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-senior-business-analyst-lead-analyst-evalueserve-com-pvt-ltd-gurgaon-gurugram-bangalore-bengaluru-2-to-7-years-110821005065?src=jobsearchDesk&sid=16315318701047674&xp=18&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-python-r-3-years-crescendo-global-leadership-hiring-india-private-l-imited-bangalore-bengaluru-delhi-ncr-mumbai-all-areas-3-to-8-years-110921000469?src=jobsearchDesk&sid=16315318701047674&xp=19&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-in3-walmart-labs-bangalore-bengaluru-3-to-6-years-090921500592?src=jobsearchDesk&sid=16315318701047674&xp=20&px=1']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descp_url=[]\n",
    "\n",
    "for u in descp_tags:\n",
    "    descp_url.append(u.get_attribute('href'))\n",
    "descp_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc=[]\n",
    "for d in descp_url:\n",
    "    driver.get(d)\n",
    "    try:\n",
    "        content= driver.find_element_by_xpath(\"//*[@class='dang-inner-html' or @class='clearboth description']\").text.replace('\\n',\" \").replace('\\n\\n',\" \")\n",
    "        \n",
    "        desc.append(content)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Minumum 3 years of experience in Data Science/Machine learning  Location : PAN INDIA Exp : 3 - 7 Years  Minimum 3 year of experience in being Applied Machine Learning Engineer role Research, develop, and implement prediction, optimization, and analytics tools. Document and communicate methodology and results to technical and non-technical audiences Guide and implement best practices of curated data and evaluate ML models on large-scale data Lead design and implementation of Machine Learning algorithms, combining with rule-based optimization to deliver significant improvement in product metrics Write production ready high quality, maintainable and scalable code. Design and analyze metrics to verify model and algorithm effectiveness. Experience with data analysis languages such as Python or Scala Experience with Machine Learning tools (Azure ML, SageMaker, TensorFlow, Kubernetes, etc.) Experience with Machine Learning Languages (R, Python, .Net Core, etc.)',\n",
       " 'Introduction Software Developers at IBM are the backbone of our strategic initiatives to design, code, test, and provide industry-leading solutions that make the world run today - planes and trains take off on time, bank transactions complete in the blink of an eye and the world remains safe because of the work our software developers do. Whether you are working on projects internally or for a client, software development is critical to the success of IBM and our clients worldwide. At IBM, you will use the latest software development tools, techniques and approaches and work with leading minds in the industry to build solutions you can be proud of.  Your Role and Responsibilities IBM s Global Technology Services (GTS) business unit has embarked on a mission to be the most trusted partner to our clients and enable them with game changing technology backbone to drive competitive advantage. One of the most significant & challenging areas for our clients is Data. From identifying & capturing to curation & consumption - we would like to simplify, automate, and accelerate the data lifecycle within our client s myriad use cases. To this effect we have launched specific offering(s) and are building out a team of passionate achievers to help us define, create, market & deliver data solutions to our clients. We are looking for a passionate Data Scientists with expertise in Machine Learning, who can contribute to deliver on this vision. This is a fun and fast paced environment, where developers are empowered to innovate and learn fast is our standard operating model. As a Senior Data Scientist you will be at the forefront of this ride and get to work with end clients on a regular basis. You will be the face of GTS & evangelize the data science & ML solutions that we have to offer. You will create compelling value proposition and targeted content to significantly improve our chances of winning in the marketplace. You will defend IBM solutions and build trust with the client at all levels -operational to executive. You will help drive, qualify & close opportunities. You will be responsible for the execution and successful delivery of Data Science assignments. You will be responsible for identifying and supporting current and new hypotheses. With your understanding of complex concepts, you will translate hypotheses into actionable items that are understandable by non-technical business users. You understand challenges in the BFSI domains & can discover new avenues to apply AI/ML solutions to solve these challenges. The problems we address are significantly complex and we expect you to lead excellence in our data science methodologies. You have a distinct ability to identify and implement robust, efficient, and scalable solutions that leverage multiple techniques and/or technologies. You will Provide guidance and architecture support to platform development teams and oversee the development from initial concept to production deployment  Required Technical and Professional Expertise As a leader in Data science organization, lead multiple scrum teams to deliver innovative ML solutions in BFSI space PH.D or Master s degree in a quantitative field such as computer science, applied mathematics, statistics, physics, engineering or finance Overall Data Science, Statistical Analysis, Data Analytics & Machine Learning experience of 10 years 7 years of BFSI domain experience in implementing data science or AI solutions from exploration to production 3 years of experience in a responsible senior or team lead role managing a team of data scientists who develop robust machine learning models to solve actual business problems Expert understanding of ML Production deployments. Have atleast 3 years of experience in production grade ML design, development & deployment Work closely with internal and external stakeholders, both technical and non-technical and help translate deep ML knowledge to stakeholders. Work closely with ML engineering/Infrastructure team to help define the vision of ML training and ML inference platforms running on Cloud as well as On-prem Mentor and grow Junior data scientists in the team on both DS modelling and software engineering skills Expert ability to define Data Science model development & MLOps process, workflows, coding practices & DevOps practices Extensive overview of applied methods in statistics, machine learning and artificial intelligence Expert understanding of various AI/ML technology stacks including Cloud Based services Help define the data science development workflows from coding and architecture best practices, data strategy, to ML training and Inference platforms Demonstrated experience in creating AI/ML solutions within the BFSI space: Banking: Credit, Risk, Customer Exp, Open Banking, Digital Banking, Cross-Sell, Up-Sell, Branch Ops, Treasury, Cards Business, SME Banking, Wealth Management Insurance/Insurtech: Claims, Operations, Agency Development, Sales & Distribution, Customer Experience, Forecasting, Actuarial, Segmentation, Pricing FS/Regtech: Compliance & Regulatory, Auto, STPI, Consumer Durables, Commercial, Mortgage Knowledge of software engineering practices such as version control, continuous delivery, unit testing, documentation, release management Experience in natural language processing, text analytics, data mining, text processing or other AI subdomains and techniques Coach and lead a team of other data scientists, engineers, and other stakeholders Propose suitable technology stacks for projects to be deployed across cloud platforms and on-premise infrastructure. Solid data management and statistical modelling skills: Experience with Scala/Python, Scikit-learn, TensorFlow, Keras, NLTK, PyTorch etc Experience with leveraging best practices conducting advanced analytics projects Experience in distributed & scalable ML development. Good PoV on TinyML and Embedded AI/ML  Preferred Technical and Professional Expertise Experience with open-source distributed data processing & ML frameworks Experience working in a Linux environment Experience working within a development team setup which is building product/services Experience with presenting complex data science processes/information to non-data scientists Experience with Information Retrieval and relevant tools such as Lucene, Elasticsearch, Solr Prioritization skills; ability to manage ad-hoc requests in parallel with ongoing projects Strong experience in both classical ML modeling approaches and Deep learning based model approaches Data analysis, reporting, visualization expertise and experience with tools such as Tableau, Alteryx, Python and R at scale Good NLP knowledge and cloud experience preferred Passion, Drive and Can-do attitude Good communication skills Willingness to thrive in ambiguous environments',\n",
       " 'Use predictive modeling to increase and optimize customer experiences, revenue generation, campaign optimization and other business outcomes Work with product management to develop data use cases and embed predictive models in workflows on resource constrained platforms and cloud enabled. Selecting features, building and optimizing classifiers using machine learning and deep learning techniques Collaborates with Data Engineers to enhance data collection and ingestion/curation techniques to include information that is relevant for building analytic systems Processing, cleansing, and verifying the integrity of data used for analysis Develop processes and tools to monitor and analyze model performance and data accuracy. Life cycle management of predictive models. Adherence to compliance procedures in accordance with regulatory standards, requirements, and policies. Managing and designing the reporting environment, including data sources security, and metadata. Job Qualifications: Master s degree or PhD in Computer Science, Information management, Statistics or related field, with 3 to 5 years of experience in the Consumer or Healthcare industry manipulating data sets and building predictive models with focus on product development Experience in statistical modelling, machine learning, data mining, unstructured data analytics and natural language processing. Sound understanding of - Bayesian Modelling, Classification Models, Cluster Analysis, Neural Network, Nonparametric Methods, Multivariate Statistics, etc. Strong hands on knowledge of ML techniques like regression algorithms, K-NN, Na ve Bayes, SVM and ensemble techniques like Random forest, AdaBoost etc Having strong knowledge in unsupervised learning algorithms using Neural networks and Deep-Learning Strong knowledge in Data Wrangling and Exploration techniques to identify the patterns, trends and outliners. Deep knowledge and practical experience with data science toolkits, such as NumPy, Pandas, scikit-learn or equivalent Experience with data visualization tools, such as QlikView, Matplotlib, seaborn or equivalent tools. Proficiency in using query languages, such as SQL, PL/SQL Hands on experience in the one or more databases like Hadoop, AWS Redshift, Snowflake etc. Good applied statistics skills, such as distributions, statistical testing, regression, etc. Good ETL scripting and programming skills, such as Python, R or Scala to integrate developed solution into the proposition. A team player capable of working and integrating across cross-functional team for implementing project requirements. Experience in technical requirements gathering and documentation. Ability to work effectively and independently in a fast-paced global collaborative agile team environment with tight deadlines A flexible, pragmatic and collaborative team player with innate ability to engage with stakeholders at all levels in the organization. A self-starter with high levels of drive, energy, resilience and a desire for professional excellence with a passion for data and data science',\n",
       " \"Must Have skill sets:  Excellent knowledge of various statistical / Machine Learning / Deep Learning algorithms such as Feature Engineering/selection, Time series, Regression, Classification, Clustering, Recommendation Engine, Anomaly Detection, NLP, Reinforcement Learning etc.) 4 to 8 years of hands-on expertise in developing data science models by applying above mentioned algorithms on structured / text data, using R / Python Proficient in writing optimized query using any one of the DB query language (Hive/Impala/SQL/MongoDB etc.). Knowledge of big data is essential  Good to Have skill sets:  Visualization using any one of the technologies (Tableau, PowerBI, RShiny, matplotlib, ggplot etc.). In case of lack of skills, eagerness to learn is must Insight Generation and Story telling to end consumers Experience across end to end data science project life cycle (use case framing, data collection, data exploration, design of experiments, model development, selection and deployment, post production support) Self-motivated to learn different techniques / technologies, as per the project's need and go extra mile to bring customer delight  Educational Qualification:  Any of the following: • Bachelors in Engineering / MCA • Masters in Data Science/ Computer Applications/ Statistics/ Mathematics/ Economics/ Ops Research/ Other quantitative disciplines • MBA  Job Responsibilities: Own and execute end to end delivery of one or more than one data science model development, as per requirement provided by project/product manager Understand business requirements from Product Managers/Business Users Extract data from multiple data sources using Hadoop / SQL Develop, Validate and Operationalize predictive models using appropriate variables and ML/deep learning techniques Perform ad-hoc deep dive analysis and generate actionable insights Create technical documentation and provide post-production support for a time-bound period Communicate the results to technical as well as business stakeholders across different hierarchies\",\n",
       " \"Must Have skill sets:  Excellent knowledge of various statistical / Machine Learning / Deep Learning algorithms such as Feature Engineering/selection, Time series, Regression, Classification, Clustering, Recommendation Engine, Anomaly Detection, NLP, Reinforcement Learning etc.) 4 to 8 years of hands-on expertise in developing data science models by applying above mentioned algorithms on structured / text data, using R / Python Proficient in writing optimized query using any one of the DB query language (Hive/Impala/SQL/MongoDB etc.). Knowledge of big data is essential  Good to Have skill sets:  Visualization using any one of the technologies (Tableau, PowerBI, RShiny, matplotlib, ggplot etc.). In case of lack of skills, eagerness to learn is must Insight Generation and Story telling to end consumers Experience across end to end data science project life cycle (use case framing, data collection, data exploration, design of experiments, model development, selection and deployment, post production support) Self-motivated to learn different techniques / technologies, as per the project's need and go extra mile to bring customer delight  Educational Qualification:  Any of the following: • Bachelors in Engineering / MCA • Masters in Data Science/ Computer Applications/ Statistics/ Mathematics/ Economics/ Ops Research/ Other quantitative disciplines • MBA  Job Responsibilities: Own and execute end to end delivery of one or more than one data science model development, as per requirement provided by project/product manager Understand business requirements from Product Managers/Business Users Extract data from multiple data sources using Hadoop / SQL Develop, Validate and Operationalize predictive models using appropriate variables and ML/deep learning techniques Perform ad-hoc deep dive analysis and generate actionable insights Create technical documentation and provide post-production support for a time-bound period Communicate the results to technical as well as business stakeholders across different hierarchies\",\n",
       " 'Introduction As a Data Scientist at IBM, you will help transform our clients data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. Work with Best in Class open source and visual tools, along with the most flexible and scalable deployment options. Whether it s investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live.  Your Role and Responsibilities Work with IBM Q Start team on active exploratory research engagements to prepare for future use case commercialization within specific industry Engage and educate client data science teams to define promising areas for quantum exploration Implement quantum approaches, which includes data pre-/post-processing, running numerics and visualizing data Collaborate with industry and solutioning experts to design and shape experiments to demonstrate quantum-enabled advantage Define best practices related to information architecture, including collection, integration, organization, analysis and visualization of data for quantum-enabled impact Engage in practice development initiatives focused on building employee knowledge and skills in specific areas of expertise through coaching and development of training course material  Required Technical and Professional Expertise PhD/Masters in STEM-related fields with knowledge in Quantum Computing. 5 years of data engineering and data science experience 2 years of consulting experience within specific industries with strong domain expertise and business acumen Proficiency with classical approaches to machine learning and linear algebra, including Support Vector Machine (SVM) for linear categorization and Singular Value Decomposition (SVD) to reduce dimensionality of data Familiar with Qiskit software, including Qiskit Aqua for domain applications and Qiskit Terra for quantum circuit design and optimization Excellent ideation, facilitation and communications skills Detail-oriented team player with strong interpersonal skills and ability to take a leadership role when necessary Willingness to travel globally up to 40% once we return to a travel-safe environment. English: Fluent  Preferred Technical and Professional Expertise 2 years of experience in at least one of the industries, with knowledge of industry trends, R&D areas, and computationally intensive processes (e.g. optimization) Familiarity with Qiskit',\n",
       " 'As a Senior Data Scientist for Walmart, you ll have the opportunity to: Drive data-derived insights across a wide range of divisions by developing advanced statistical models, machine learning algorithms and computational algorithms based on business initiatives Direct the gathering of data, assessing data validity and synthesizing data into large analytics datasets to support project goals Utilize big data analytics and advanced data science techniques to identify trends, patterns, and discrepancies in data. Determine additional data needed to support insights Build and train statistical models and machine learning algorithms Apply your semantic, natural language processing and understanding expertise where required Use deep learning and image recognition project goals Computer Vision will be an important focus area for this role Productionize the models and make those available at scale Build and maintain end to end Machine Learning pipelines Be comfortable with ambiguity and uncertainty and the eagerness to change the world in a huge way by being a self-motivated learner and builder Communicate recommendations to business partners and influencing future plans based on insights Your Responsibility Play a key role to solve complex problems, pivotal to Walmart s business and drive actionable insights from petabytes of data Utilize product mindset to build, scale and deploy holistic data science products after successful prototyping Demonstrate incremental solution approach with agile and flexible ability to overcome practical problems Partner with senior team members to assess customer needs and define business questions Clearly articulate and present recommendations to business partners, and influence future plans based on insights Work with customer centric mindset to deliver high quality business driven analytic solution Drive innovation in approach, method, practices, process, outcome, delivery, or any component of end-to-end problem solving Demonstrates up-to-date expertise and applies this to the development, execution, and improvement of action plans Preferred Qualifications Bachelors degree in Statistics, Mathematics, Computer Science or a related field and 8 years experience in an analytics/DS related field, or, Masters degree in Statistics, Mathematics, Computer Science or a related field and 6 years experience in an analytics/DS related field. High proficiency in data mining, modeling, validation and insight generation. Excellent working knowledge of statistics, mathematics, machine learning, data mining, deep learning High proficiency in coding including Python and SQL Experience with databases (for example, DB2, Oracle, SQL Server) Experience with Big Data technologies such as Pig, Hive and/or Spark Ability to work with large data sets. Has sound understanding of big data technology stack Understanding of cloud computing platforms and large-scale databases Proven ability to collaborate and work in teams Excellent with communications and stakeholder engagement Data science publications in recognized platforms/journals Proven ability to work in agile mode on data science sprint projects',\n",
       " 'Introduction As a Data Scientist at IBM, you will help transform our clients data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. Work with Best in Class open source and visual tools, along with the most flexible and scalable deployment options. Whether it s investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live.  Your Role and Responsibilities Data Science Consultants are adept across data science techniques using open source tools to solve varied use cases for our clients They work to build strong, enduring relationships with client staff based on innovation, trust and service excellence. They are accountable for successful delivery of complex data science engagements adhering to client s requirements and timelines They learn constantly and lead adoption of emerging technologies and approaches in their processes benefiting the client & IBM overall.  Required Technical and Professional Expertise BTech (with 8 years of relevant experience) or Masters (with 6 years of relevant experience) in Operations Research, Applied Mathematics/ Statistics/ Econometrics, Electrical or Systems Engineering, Physics or similar highly quantitative field Strong ability to transform business requirements into data science formulations and implement the solutions in an efficient and scalable fashion Sound understanding of data science concepts, model development & performance tuning processes as well as coding, version control and CI/CD best practices Demonstrated extensive experience in building and deploying production quality models in a live digital environment using data pipelines and ML Ops frameworks including handling model drift, retraining and version control lifecycle Highly skilled in Python and various data science related libraries of Python including TensorFlow, Keras, Sci-Kit Lean, Pandas, Numpy and PySpark Experience in Convolutional Neural Network / Computer Vision projects using TensorFlow, PyTorch and leveraging public / open-source libraries (VGG16, ImageNet, YOLO, OpenCV, etc) as well as ability to tweak, modify these CNN architectures when required for a specific business problem. Demonstrated ability of scoping, executing and scaling multiple data science deliverables on their own Must have worked in developing and deploying models using more than one cloud platform (AWS, Azure, GCP, IBM) Ability to handle multiple projects as an individual contributor and as a lead / mentor to other team members managed directly or indirectly on a project / assignment Excellent interpersonal and stakeholder management skills including ability to interact and present to senior stakeholders',\n",
       " 'As a Data Scientist at IBM, you will help transform our clients data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. Work with Best in Class open source and visual tools, along with the most flexible and scalable deployment options. Whether it s investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live.  Your Role and Responsibilities Data Science Consultants are adept across data science techniques using open source tools to solve varied use cases for our clients They work to build strong, enduring relationships with client staff based on innovation, trust and service excellence. They are accountable for successful delivery of complex data science engagements adhering to client s requirements and timelines They learn constantly and lead adoption of emerging technologies and approaches in their processes benefiting the client & IBM overall. Required Technical and Professional Expertise BTech (with 8 years of relevant experience) or Masters (with 6 years of relevant experience) in Operations Research, Applied Mathematics/ Statistics/ Econometrics, Electrical or Systems Engineering, Physics or similar highly quantitative field Strong ability to transform business requirements into data science formulations and implement the solutions in an efficient and scalable fashion Sound understanding of data science concepts, model development & performance tuning processes as well as coding, version control and CI/CD best practices Demonstrated extensive experience in building and deploying production quality models in a live digital environment using data pipelines and ML Ops frameworks including handling model drift, retraining and version control lifecycle Highly skilled in Python and various data science related libraries of Python including TensorFlow, Keras, Sci-Kit Lean, Pandas, Numpy and PySpark Experience in Convolutional Neural Network / Computer Vision projects using TensorFlow, PyTorch and leveraging public / open-source libraries (VGG16, ImageNet, YOLO, OpenCV, etc) as well as ability to tweak, modify these CNN architectures when required for a specific business problem. Demonstrated ability of scoping, executing and scaling multiple data science deliverables on their own Must have worked in developing and deploying models using more than one cloud platform (AWS, Azure, GCP, IBM) Ability to handle multiple projects as an individual contributor and as a lead / mentor to other team members managed directly or indirectly on a project / assignment Excellent interpersonal and stakeholder management skills including ability to interact and present to senior stakeholders',\n",
       " '  Skills Required Skills: Data Science, Machine Learning, Deep Learning, Python, NLP Desired Skills: Computer Vision Roles and responsibilities Experience in Data Modelling, R, Python, SQL, Data Science, Machine Learning, Deep Learning, NLP, Statistics Have ability to solve Business problems using Data Should possess extensive knowledge of and experience in applying data mining and machine learning techniques on large amount of datasets High level of proficiency in statistical tools like R, Python Candidate will be expected to communicate analytical results in a way that is meaningful for business stakeholders and provides actionable insights. Have the ability to discover new opportunities where advanced analytical techniques can be leveraged for solving business problems Good to Have Expertise in programming languages like Java/C/C /Python Experience with relational databases and SQL is good to have Experience in audio and video analytics Relevant experience in Big Data platforms like Hadoop eco-system Come up with innovative algorithms and solutions Staffing Type:Permanent',\n",
       " 'Design, coordinate, and implement data driven business and technology solutions to support innovation initiatives Communicate complex models, analysis and recommendations in a clear and precise manner Provide thought leadership in statistical modeling and machine learning/ AI. NLP and Deep Learning are the two focus areas Deliver actionable insights to stakeholders through rich visualization and presentation Manage priorities between research and deliverables effectively Collaborate actively with topic owners to understand and develop advanced analytics / data science Your Qualifications Bachelor s degree in Engineering / Analytics or Master s Degree in Statistics/Computer Applications/ IT/Analytics /any discipline related to Data Science / Analytics. 7 years of progressive experience in Machine learning/Deep learning preferably working with packages like NLTK, BERT, ELMo etc Fluent in Python and have experience with NLP libraries like , Spacy, Genism, Glove, doc2vec etc. Exposure to Microsoft LUIS will be preferred Possess advanced knowledge of the HuggingFace libraries and concepts like tokens, tokenization, stemming, lemmatization, regex. Solid command on statistics and ability to connect theory and practice of data mining, machine learning to solve real-world use case l Strong working knowledge of Python (BERT, GPT, genism, SpaCy, tensorflow, Theano, PyTorch, SciPy, scikit-learn, pandas), SQL, Unix (awk, sed, bash) for data wrangling, data analysis, modeling. Knowledgeable in Natural Language processing (NLP) and quantitative analysis Previous experience building chatbots for Customer Service / specific business verticals (Bonus) Interesting side projects or Kaggle competition results (Bonus) Excellent critical thinking ability, result orientation and project management skills Sound verbal and written communication skills',\n",
       " 'Position Responsibilities o Solve business problems by applying advanced Machine Learning algorithms and complex statistical models on large volumes of data. o Build, scale and deploy holistic data science products after successful prototyping. o Clearly articulate and present recommendations to business partners, and influence future plans based on insights. o Follow industry best practices, stay up to date with the state of the art in machine learning research and practice, drive innovation by contributing to the latest applied research in data science through publications and patents. o Promote and support company policies, procedures, mission, values, and standards of ethics and integrity. Position Requirements o Deep knowledge of the foundations of machine learning and statistics - can easily understand and implement a machine learning research paper. o Solid experience working with state-of-the-art supervised and unsupervised machine learning algorithms on real-world problems, preferably in ecommerce domain. o Strong Python coding skills and able to work with at least one other programming language such as Java/Scala. o Ability to work in a big data ecosystem - expert in SQL/Hive and ability to work with Spark. o Strong ability to understand the business and good stakeholder management capabilities. Qualifications o PhD with > 2 years of experience / 4-year bachelor s degree with > 7 years of experience / Master s degree with > 5 years of experience. Educational qualifications should be preferably in Computer Science or a related area. Experience should be relevant to the role. Good to have: o Experience in ecommerce domain. o Demonstrated success in data science platforms like Kaggle.',\n",
       " 'Hello, We are hiring on behalf of one of the largest BPO/ Consulting services. The skills rquired are Natural Language Processing, Python, Data Science and Machine Learning.  Title: Manager / Sr. Manager Location:Bangalore , Gurugram, Mumbai Duration : Fulltime Max Notice:1 Month',\n",
       " 'CRISIL (formerly Credit Rating Information Services of India Limited) is an Indian analytical company providing ratings, research, and risk and policy advisory services and is a subsidiary of American company S&P Global  We are looking Data Scientist for Mumbai & Bangalore location Candidates who can join immediately or within 30-45 need only apply  Please refer below JD for your reference-  Job Description Data scientist: Client oriented approach to problem solving. Individual should be able to have a holistic view of multiple businesses and develop analytic solutions accordingly. Own and deliver multiple and complex analytic projects. This would require an understanding of business context, conversion of business problems in modeling, and implementing such solutions to create business value. Always up to date with the latest use cases of modeling community, machine learning and deep learning algorithms and share knowledge within the team. Proficiency in basic statistics, hypothesis testing, segmentation and predictive modeling. Ability to translate and articulate technical thoughts and ideas to a larger audience including influencing skills with peers and senior management. Strong project management skills. Ability to coach and mentor juniors. Eagerness to work on new and challenging tasks on a regular basis with an ability to research new ways of doing things better/efficiently. Contribute to organizational initiatives in wide ranging areas including competency development, training, organizational building activities etc. Skills  Basic Qualifications  Bachelors Degree with 2+ years of experience in data analytics, Hands-on experience in Python / SAS or R programing along with strong experience in SQL and Excel Macros. Experienced in working with large and multiple datasets, data warehouses and ability to pull data using relevant programs and coding. Well versed with necessary data preprocessing and feature engineering skills. At least 2 years of experience implementing Machine learning algorithms such as Random Forest and Gradient Boosting in solving business problems such as Default classification and macroeconomic forecasting. At least 1 year of experience implementing deep learning techniques like neural networks Exposure to deep learning packages like Tensorflow Strong background in Statistical Analysis Background in BFSI space will be preferred',\n",
       " 'Required Technical and Professional Expertise • 6+ years of industry work experience in data scientist projects • Master’s degree or higher in Statistics/Math/Computer Science or related field • Background in applied statistical modeling on large experimental or observational data sets • Experience extracting data from a variety of sources, and a desire to expand those skills (working knowledge SQL is required, Spark is a plus) • Experience with one or more statistical or machine learning software such as R, Python, etc. • Must showcase past work through published articles/GitHub/social media  Preferred Technical and Professional Expertise • Knowledge of distributed computing systems, e.g. Cosmos, Spark, Hadoop, and relational database management system • PhD. in Statistics is preferred • You love collaborative environments that use agile methodologies to encourage creative design thinking and find innovative ways to develop with cutting edge technologies • Ambitious individual who can work under their own direction towards agreed targets/goals and with creative approach to work • Intuitive individual with an ability to manage change and proven time management • Proven interpersonal skills while contributing to team effort by accomplishing related results as needed',\n",
       " 'Roles and Responsibilities Requirements :  - 6-9 years of strong experience in data mining, machine learning and statistical analysis.  - BS/ MS/ PhD in Computer Science, Statistics, Applied Math, or related areas from Premier institutes ( only IITs / IISc / BITS / Top NITs or top US university should apply)  - Ability to lead and deliver in a fast-paced start-up environment.  - Fluency in tools such as Python/ R/ Matlab etc.  - Strong intuition for data and Keen aptitude on large scale data analysis  - Excellent written and verbal communication skills.  - Ability to collaborate across teams and strong interpersonal skills.',\n",
       " 'Job Description Understand and design analytical solutions to business problems leveraging data science Understand and get requirements from Stakeholders Propose and execute solutions and present deliverables to stakeholders Manage and optimize deliverables Mentor and train new team members Develop POCs to enhance the teams capability  Requirements Understanding of mathematical, statistical, and theoretical foundations of statistics and machine learning (ML) and parametric and non-parametric models Knowledge of advanced data mining techniques, curating, processing, and transforming data to produce datasets Use statistical techniques and ML methods for predictive modeling / classification of problems around clients, distribution, sales, marketing, client profiles, and segmentation Provide relevant and actionable recommendations / insights for businesses Understanding of ML lifecycle that includes feature engineering, training, validation, scaling, deployment, scoring, monitoring, and feedback loop Expertise in SAS Visual Analytics, Tableau, and Python Expert in Python / R / SAS Experience with cloud computing infrastructure, such as AWS / Azure / GCP Able to develop, test, and deploy models on cloud / web  Education and Experience BE / B.Tech. / MBA / M.Stat. / M.SC. or equivalent degree in Quant. from a reputed institute 2-8 years of relevant experience',\n",
       " 'Data Scientist- Python/R (3+ Years)  Data Scientist job opportunity in Bengaluru/Mumbai/Gurgaon for a professional holding at least 3 years of experience in Data science, using Python/R. Our client is looking for a professional who is keen to grow their career in Data Analysis as an individual contributor as well as a team leader with some client interface. If this sounds exciting, apply with us!  Location- Bengaluru/Mumbai/Gurgaon  YOUR FUTURE EMPLOYER:  One of the top analytics firm.  RESPONSIBILITIES:  Solve business problems & develop a business solution Project management Client relationship management Sales Support & account growth Firm building  REQUIREMENTS:  The overall experience of Minimum 2 to 6 years of hands-on experience in running Advanced analytics projects Knowledge of predictive/prescriptive analytics including Machine Learning algorithms (Supervised and Unsupervised) and deep learning algorithms, Artificial Neural Networks (CUDA, Keras, Tensorflow) Experience leading the end-to-end design, development, and deployment of predictive modeling solutions. Advanced SQL skills with Teradata, SQL Server, Hive and Spark experience. Deep expertise in applying machine learning to solve a class of AI problems such as NLU/NLP, Reinforcement Learning, Voice Biometrics, Text Mining, and Intelligent Process Automation  WHAT IS IN IT FOR YOU?  A high-performance culture with phenomenal career progression. Fast track career growth. Work in a fast-paced environment in and established brand.  REACH US:  If you think this role is aligned with your career, kindly write me an email along with your updated CV on ravjot.kaur@crescendogroup.in for a confidential discussion on the role.  DISCLAIMER: We are an equal opportunity recruitment firm and value diversity in the talent we identify for our clients. We do not discriminate on the basis of race, religion, colour, origin, gender, sexual orientation, age, marital status, veteran status, or disability status.',\n",
       " 'Your Responsibility Develop the algorithms to generate better demand forecast Use predictive modeling methods for demand forecasting Develop the production level code for implementation of algorithms Research on the newer technologies and algorithms, to improve forecast accuracy Design the Data Science experiments, execute them and record the results Adopt Wal-Mart s quality standards and develop and recommend process standards and best practices across the retail industry Research, learn adapt new technologies to solve problems improve existing solutions Participate in events to build innovative solutions Adhere to company policies, procedures, mission, values, and standards of ethics and integrity. Our Ideal Candidate Technical strong, proficient in Data Science (Algorithms and programming - R, Python) well versed with Data Science toolkits (Scikit-learn, Tensorflow) and basic Data Engineering toolkit (data.table, pandas). High performing associate with excellent communication skills, proven skill sets for building high performance Data Science teams that can work across multiple geographies, with strong customer focus and deliver across multiple technologies Your Qualifications B.E/B.Tech from a reputed institution Minimum of 3 years of Data Science Experience Command over atleast one of the Languages extensively used by Data Scientists - R, Python Good understanding of predictive modelling techniques - Linear/Non-Linear Models, Ensemble methods, Kernel Methods, Artificial Neural Networks Good Understanding of optimization techniques - NN, Gradient Descent, Genetic Algorithms Hand-on experience in Data Preperation tools - pandas, data.table Good understanding in Big Data Ecosystem - Hadoop and Spark Should be a fast learner and quickly adapt to new technologies. Prefer individuals with High Ownership and commitment.']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets first check the length of each of the list, to check if the lenght of all of the lists are not equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 19\n"
     ]
    }
   ],
   "source": [
    "print(len(job_titles),len(company_names),len(location_list),len(desc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "JobDF = pd.DataFrame({\"Job Title\":job_titles[0:10],\"Company\":company_names[0:10],\"Location\":location_list[0:10],\"Job Description\":desc[0:10]})\n",
    "JobDF.reset_index(drop=True,inplace = True)\n",
    "JobDF.index+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hiring For Data Scientist</td>\n",
       "      <td>Tata Consultancy Services Ltd.</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "      <td>Minumum 3 years of experience in Data Science/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lead Data Scientist BFSI</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>Introduction Software Developers at IBM are th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Use predictive modeling to increase and optimi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Allegis Services India Pvt. Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Must Have skill sets:  Excellent knowledge of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Allegis Services India Pvt. Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Must Have skill sets:  Excellent knowledge of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>Introduction As a Data Scientist at IBM, you w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Walmart Labs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>As a Senior Data Scientist for Walmart, you ll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Airbnb</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Introduction As a Data Scientist at IBM, you w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>As a Data Scientist at IBM, you will help tran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Skills Required Skills: Data Science, Machin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Job Title                           Company  \\\n",
       "1            Hiring For Data Scientist    Tata Consultancy Services Ltd.   \n",
       "2             Lead Data Scientist BFSI            IBM India Pvt. Limited   \n",
       "3             Associate Data Scientist             Philips India Limited   \n",
       "4                       Data Scientist  Allegis Services India Pvt. Ltd.   \n",
       "5                       Data Scientist  Allegis Services India Pvt. Ltd.   \n",
       "6   Data Scientist: Advanced Analytics            IBM India Pvt. Limited   \n",
       "7                Senior Data Scientist                      Walmart Labs   \n",
       "8                Senior Data Scientist                            Airbnb   \n",
       "9                    Sr Data Scientist            IBM India Pvt. Limited   \n",
       "10                   Sr Data Scientist            IBM India Pvt. Limited   \n",
       "\n",
       "                                            Location  \\\n",
       "1   Chennai, Bangalore/Bengaluru, Mumbai (All Areas)   \n",
       "2                                Bengaluru/Bangalore   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bengaluru/Bangalore   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bengaluru/Bangalore   \n",
       "10                               Bangalore/Bengaluru   \n",
       "\n",
       "                                      Job Description  \n",
       "1   Minumum 3 years of experience in Data Science/...  \n",
       "2   Introduction Software Developers at IBM are th...  \n",
       "3   Use predictive modeling to increase and optimi...  \n",
       "4   Must Have skill sets:  Excellent knowledge of ...  \n",
       "5   Must Have skill sets:  Excellent knowledge of ...  \n",
       "6   Introduction As a Data Scientist at IBM, you w...  \n",
       "7   As a Senior Data Scientist for Walmart, you ll...  \n",
       "8   Introduction As a Data Scientist at IBM, you w...  \n",
       "9   As a Data Scientist at IBM, you will help tran...  \n",
       "10    Skills Required Skills: Data Science, Machin...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JobDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company_name, experience_required.\n",
    "The location filter to be used is “Delhi/NCR”\n",
    "The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field \n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Sourabh\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.naukri.com/' \n",
    "driver.get(url)\n",
    "\n",
    "jobsearch = driver.find_element_by_id('qsb-keyword-sugg')\n",
    "jobsearch\n",
    "jobsearch.send_keys(\"Data Scientist\")\n",
    "search = driver.find_element_by_class_name('btn')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_filter = driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[1]/div[2]/div[3]\")\n",
    "location_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_filter = driver.find_element_by_xpath(\"//span[@title='3-6 Lakhs']\")\n",
    "salary_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []\n",
    "company = []\n",
    "locations = []\n",
    "exp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tag = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "company_tag = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "location_tag = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span[1]\")\n",
    "exp_tag = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")\n",
    "\n",
    "for i in title_tag:\n",
    "    job_title.append(i.text)\n",
    "for c in company_tag:\n",
    "    company.append(c.text)\n",
    "company\n",
    "for l in location_tag:\n",
    "    locations.append(l.text)\n",
    "for x in exp_tag:\n",
    "    exp.append(x.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sumup in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = pd.DataFrame({\"Job Title\":job_title[0:10],\"Company\":company[0:10],\"Experience\":exp[0:10],\"Location\":locations[0:10]})\n",
    "job.reset_index(drop=True,inplace = True)\n",
    "job.index+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist / Data Analyst / Business Analy...</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "      <td>Ghaziabad, Faridabad, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist/ Machine Learning Engineer</td>\n",
       "      <td>Creative Hands HR Consultancy</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Ahmedabad, Gurga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist / Data Analyst</td>\n",
       "      <td>CARS24</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Only Fresher / Data Scientist / Data Analyst /...</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist / Data Analyst / Business Analy...</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "      <td>Noida, New Delhi, Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>R Systems International Ltd.</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>PROCESS NINE TECHNOLOGIES PVT.LTD.</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - Insurance</td>\n",
       "      <td>Huquo Consulting Pvt. Ltd</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Noida, Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - WFH - MIND Infotech</td>\n",
       "      <td>MOTHERSONSUMI INFOTECH &amp; DESIGNS LIMITED</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Pune, Chennai, Bangalore/Bengaluru, Delhi / NC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Junior Data Scientists &amp; Engineers</td>\n",
       "      <td>PY Consultancy</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>New Delhi, Delhi / NCR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job Title  \\\n",
       "1   Data Scientist / Data Analyst / Business Analy...   \n",
       "2           Data Scientist/ Machine Learning Engineer   \n",
       "3                       Data Scientist / Data Analyst   \n",
       "4   Only Fresher / Data Scientist / Data Analyst /...   \n",
       "5   Data Scientist / Data Analyst / Business Analy...   \n",
       "6                                      Data Scientist   \n",
       "7                                      Data Scientist   \n",
       "8                          Data Scientist - Insurance   \n",
       "9                Data Scientist - WFH - MIND Infotech   \n",
       "10                 Junior Data Scientists & Engineers   \n",
       "\n",
       "                                     Company Experience  \\\n",
       "1                  GABA Consultancy services    0-0 Yrs   \n",
       "2              Creative Hands HR Consultancy    0-0 Yrs   \n",
       "3                                     CARS24    1-5 Yrs   \n",
       "4                  GABA Consultancy services    0-0 Yrs   \n",
       "5                  GABA Consultancy services    0-0 Yrs   \n",
       "6               R Systems International Ltd.    3-6 Yrs   \n",
       "7         PROCESS NINE TECHNOLOGIES PVT.LTD.    1-3 Yrs   \n",
       "8                  Huquo Consulting Pvt. Ltd    2-7 Yrs   \n",
       "9   MOTHERSONSUMI INFOTECH & DESIGNS LIMITED    3-7 Yrs   \n",
       "10                            PY Consultancy    0-3 Yrs   \n",
       "\n",
       "                                             Location  \n",
       "1                   Ghaziabad, Faridabad, Delhi / NCR  \n",
       "2   Hyderabad/Secunderabad, Pune, Ahmedabad, Gurga...  \n",
       "3                                    Gurgaon/Gurugram  \n",
       "4                Noida, Gurgaon/Gurugram, Delhi / NCR  \n",
       "5                  Noida, New Delhi, Gurgaon/Gurugram  \n",
       "6                                               Noida  \n",
       "7                                    Gurgaon/Gurugram  \n",
       "8                             Noida, Gurgaon/Gurugram  \n",
       "9   Pune, Chennai, Bangalore/Bengaluru, Delhi / NC...  \n",
       "10                             New Delhi, Delhi / NCR  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company.\n",
    "\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/index.htm\n",
    "2. Enter “Data Scientist” in “Job Title,Keyword,Company” field and enter “Noida” in “location” field.\n",
    "3. Then click the search button. You will land up in the below page:\n",
    "4. Then scrape the data for the first 10 jobs results you get in the above shown page.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Sourabh\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.glassdoor.co.in/index.htm' \n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobsearch = driver.find_element_by_id('sc.keyword')\n",
    "jobsearch\n",
    "jobsearch.send_keys(\"Data Scientist\")\n",
    "location = driver.find_element_by_id('sc.location')\n",
    "location.send_keys(\"Noida\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn = driver.find_element_by_xpath(\"//button[@class='gd-ui-button ml-std col-auto search__SearchStyles__newSearchButton css-1dqvyh7']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "company = []\n",
    "posting_ago = []\n",
    "Rating = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"0e0e88db713f2da1f8c8f88260b4a1e7\", element=\"38f1c57b-877b-416b-bb28-407ec61c9b52\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0e0e88db713f2da1f8c8f88260b4a1e7\", element=\"df7a61b7-dc28-4126-a705-48f460657ff1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0e0e88db713f2da1f8c8f88260b4a1e7\", element=\"cac65ae9-1ad0-4c0e-8310-a229984e2343\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0e0e88db713f2da1f8c8f88260b4a1e7\", element=\"881fdd91-fe93-439e-841f-1d43ff9a16bc\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0e0e88db713f2da1f8c8f88260b4a1e7\", element=\"4a474118-39e4-4b1d-927e-a30d69740861\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0e0e88db713f2da1f8c8f88260b4a1e7\", element=\"c0699096-1202-4299-9170-b4c2f63f60c1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0e0e88db713f2da1f8c8f88260b4a1e7\", element=\"2b811d99-56ce-424e-b87c-786b2d2a11ad\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0e0e88db713f2da1f8c8f88260b4a1e7\", element=\"70e98a6e-697f-467e-9e48-345948e95552\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0e0e88db713f2da1f8c8f88260b4a1e7\", element=\"4fcc4744-7983-459d-84d8-31fe96ffeddf\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0e0e88db713f2da1f8c8f88260b4a1e7\", element=\"a31285c6-e4c7-4835-9daf-a28435528fd7\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0e0e88db713f2da1f8c8f88260b4a1e7\", element=\"e6cdcc40-b7d5-4648-85e5-ba8065104ae2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0e0e88db713f2da1f8c8f88260b4a1e7\", element=\"d1dc2e03-eca2-4f5b-b27e-b3123547e9c8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0e0e88db713f2da1f8c8f88260b4a1e7\", element=\"f95f3d50-389c-492e-919a-5d4e98417867\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0e0e88db713f2da1f8c8f88260b4a1e7\", element=\"818e372d-dfc7-4732-a7fe-2f41ac333a95\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0e0e88db713f2da1f8c8f88260b4a1e7\", element=\"734df2d1-ef0f-403e-a8bc-2720b07ceb8a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0e0e88db713f2da1f8c8f88260b4a1e7\", element=\"25460629-e8e7-4202-98d2-eb0ceaa59f07\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0e0e88db713f2da1f8c8f88260b4a1e7\", element=\"20134e85-051a-4366-bfe3-2763d8bff5e5\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0e0e88db713f2da1f8c8f88260b4a1e7\", element=\"6bed35ef-4a9a-45d1-a084-86d3215e7c52\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0e0e88db713f2da1f8c8f88260b4a1e7\", element=\"ca3df6f0-01eb-4fe7-9f56-15ccc1f52ae8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0e0e88db713f2da1f8c8f88260b4a1e7\", element=\"fb502aea-770b-4bca-8f4f-60ec9a054031\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0e0e88db713f2da1f8c8f88260b4a1e7\", element=\"3dfac120-09f6-4df5-8a00-7fc4ebdea24b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0e0e88db713f2da1f8c8f88260b4a1e7\", element=\"f1630faa-a7bc-4d6d-a1cc-3e692e461264\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0e0e88db713f2da1f8c8f88260b4a1e7\", element=\"4c016b2f-59cc-4e4a-ad2f-23b638a55633\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0e0e88db713f2da1f8c8f88260b4a1e7\", element=\"ca8f7cc3-d759-4f72-bc0c-ab232722f368\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0e0e88db713f2da1f8c8f88260b4a1e7\", element=\"e8febe1b-28db-45a8-9d7a-0efc6b048935\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0e0e88db713f2da1f8c8f88260b4a1e7\", element=\"7eb5752e-241d-410c-855e-f99460c67b40\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0e0e88db713f2da1f8c8f88260b4a1e7\", element=\"fe128334-f1d5-45e8-8eb2-a7ed110c7a39\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0e0e88db713f2da1f8c8f88260b4a1e7\", element=\"40d1deb9-88e4-41e3-b1b2-9fab93731cdb\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0e0e88db713f2da1f8c8f88260b4a1e7\", element=\"2ebf8f89-e4af-4b8d-a272-c9d2aefe4aa7\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0e0e88db713f2da1f8c8f88260b4a1e7\", element=\"f525e508-258b-45d8-9bad-ec2d8f266065\")>]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the element for Company Name using xpath\n",
    "company_name = driver.find_elements_by_xpath(\"//div[@class='d-flex justify-content-between align-items-start']//a\")\n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Liberin Technologies Private Limited',\n",
       " 'AlgoScale Technologies Private Limited',\n",
       " 'Noisy Lion',\n",
       " 'Salasar New Age Technologies',\n",
       " 'Techlive',\n",
       " 'Grail Insights',\n",
       " 'Grail Insights',\n",
       " 'Lenskart',\n",
       " 'Salasar New Age Technologies',\n",
       " 'Newgen Software',\n",
       " 'Genpact',\n",
       " 'Biz2Credit Inc',\n",
       " 'Ericsson',\n",
       " 'IBM',\n",
       " 'Crowe',\n",
       " 'SearchUrCollege',\n",
       " 'limeroad.com',\n",
       " 'Airtel India',\n",
       " 'NEC Opportunities',\n",
       " 'Crypto Mize',\n",
       " 'ING',\n",
       " 'Monotype',\n",
       " 'Emerging India Group',\n",
       " 'Saishaa Services',\n",
       " 'Ishatva Management Solutions',\n",
       " 'Badatya Private Limited',\n",
       " 'Adobe',\n",
       " 'CSTEP',\n",
       " 'CRMNEXT',\n",
       " 'xtLytics']"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in company_name:\n",
    "    company.append(i.text)\n",
    "company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['30d+',\n",
       " '19d',\n",
       " '',\n",
       " '30d+',\n",
       " '30d+',\n",
       " '5d',\n",
       " '5d',\n",
       " '7d',\n",
       " '30d+',\n",
       " '30d+',\n",
       " '7d',\n",
       " '30d+',\n",
       " '12d',\n",
       " '23d',\n",
       " '30d+',\n",
       " '30d+',\n",
       " '19d',\n",
       " '24d',\n",
       " '26d',\n",
       " '27d',\n",
       " '10d',\n",
       " '4d',\n",
       " '30d+',\n",
       " '21d',\n",
       " '14d',\n",
       " '16d',\n",
       " '30d+',\n",
       " '30d+',\n",
       " '30d+',\n",
       " '30d+']"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_posted = driver.find_elements_by_xpath(\"//div[@class='d-flex align-items-end pl-std css-17n8uzw']\")\n",
    "\n",
    "for d in job_posted:\n",
    "    posting_ago.append(d.text)\n",
    "posting_ago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '3.9',\n",
       " '3.9',\n",
       " '',\n",
       " '',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.6',\n",
       " '',\n",
       " '3.3',\n",
       " '3.8',\n",
       " '4.2',\n",
       " '4.1',\n",
       " '3.9',\n",
       " '3.8',\n",
       " '',\n",
       " '',\n",
       " '3.8',\n",
       " '',\n",
       " '5.0',\n",
       " '4.0',\n",
       " '3.9',\n",
       " '2.4',\n",
       " '',\n",
       " '',\n",
       " '4.5',\n",
       " '4.4',\n",
       " '3.2',\n",
       " '3.7',\n",
       " '3.0']"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " Rating_tag=[i.text if i != '' else None for i in  driver.find_elements_by_xpath(\"//div[@class='d-flex flex-column job-search-key-1pzmdmc e1rrn5ka1']\")]  \n",
    "\n",
    "\n",
    "Rating_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating_tag=[\"N/A\" if i =='' else i for i in Rating_tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['N/A',\n",
       " '3.9',\n",
       " '3.9',\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " '3.5',\n",
       " '3.5',\n",
       " '3.6',\n",
       " 'N/A',\n",
       " '3.3',\n",
       " '3.8',\n",
       " '4.2',\n",
       " '4.1',\n",
       " '3.9',\n",
       " '3.8',\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " '3.8',\n",
       " 'N/A',\n",
       " '5.0',\n",
       " '4.0',\n",
       " '3.9',\n",
       " '2.4',\n",
       " 'N/A',\n",
       " 'N/A',\n",
       " '4.5',\n",
       " '4.4',\n",
       " '3.2',\n",
       " '3.7',\n",
       " '3.0']"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rating_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30\n"
     ]
    }
   ],
   "source": [
    "print(len(company),len(posting_ago),len(Rating_tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "Job = pd.DataFrame({\"Company\":company[0:10],\"posting_ago\":posting_ago[0:10],\"Rating\":Rating_tag[0:10]})\n",
    "Job.reset_index(drop=True,inplace = True)\n",
    "Job.index+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>posting_ago</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Liberin Technologies Private Limited</td>\n",
       "      <td>30d+</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AlgoScale Technologies Private Limited</td>\n",
       "      <td>19d</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Noisy Lion</td>\n",
       "      <td></td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>30d+</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Techlive</td>\n",
       "      <td>30d+</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Grail Insights</td>\n",
       "      <td>5d</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Grail Insights</td>\n",
       "      <td>5d</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lenskart</td>\n",
       "      <td>7d</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>30d+</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Newgen Software</td>\n",
       "      <td>30d+</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Company posting_ago Rating\n",
       "1     Liberin Technologies Private Limited        30d+    N/A\n",
       "2   AlgoScale Technologies Private Limited         19d    3.9\n",
       "3                               Noisy Lion                3.9\n",
       "4             Salasar New Age Technologies        30d+    N/A\n",
       "5                                 Techlive        30d+    N/A\n",
       "6                           Grail Insights          5d    3.5\n",
       "7                           Grail Insights          5d    3.5\n",
       "8                                 Lenskart          7d    3.6\n",
       "9             Salasar New Age Technologies        30d+    N/A\n",
       "10                         Newgen Software        30d+    3.3"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/Salaries/index.htm\n",
    "2. Enter “Data Scientist” in Job title field and “Noida” in location field.\n",
    "3. Click the search button.\n",
    "4. After that you will land on the below page\n",
    "You have to scrape whole data from this webpage\n",
    "5. Scrape data for first 10 companies. Scrape the min salary, max salary, company name, Average salary and rating of the company.\n",
    "6.Store the data in a dataframe.\n",
    "Note that all of the above steps have to be done by coding only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Sourabh\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.glassdoor.co.in/Salaries/index.htm' \n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobsearch = driver.find_element_by_id('KeywordSearch')\n",
    "jobsearch\n",
    "jobsearch.send_keys(\"Data Scientist\")\n",
    "location = driver.find_element_by_id('LocationSearch')\n",
    "location.send_keys(\"Noida\")\n",
    "search = driver.find_element_by_xpath('/html/body/div[3]/div/div[1]/div[1]/div/div/form/button')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "company = []\n",
    "job_title = []\n",
    "Rating = []\n",
    "sals = []\n",
    "avg_sal = []\n",
    "sal_num = []\n",
    "Rating_tag = driver.find_elements_by_xpath(\"//span[@class='m-0 css-kyx745']\")\n",
    "company_tag = driver.find_elements_by_xpath(\"//a[@class='css-f3vw95 e1aj7ssy3']\")\n",
    "title_tag = driver.find_elements_by_xpath(\"//div[@class='col-12 col-lg px-xsm']//span\")\n",
    "sal_num_tag = driver.find_elements_by_xpath(\"//div[@class='col-12 col-lg-auto']//span\")\n",
    "sals_tag = driver.find_elements_by_xpath(\"//div[@class='d-none d-lg-block']//p\")\n",
    "avg_sal_tag = driver.find_elements_by_xpath(\"//div[@class='col-12 col-lg-4 px-lg-0 d-flex align-items-baseline']\")\n",
    "for i in company_tag:\n",
    "    company.append(i.text)\n",
    "for j in title_tag :\n",
    "    job_title.append(j.text)\n",
    "for r in Rating_tag:\n",
    "    Rating.append(r.text)\n",
    "for n in sal_num_tag:\n",
    "    sal_num.append(n.text)\n",
    "for m in sals_tag:\n",
    "    sals.append(m.text)\n",
    "for a in avg_sal_tag:\n",
    "    avg_sal.append(a.text.replace(\"\\n \",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹6,28,021/yr',\n",
       " '₹9,08,246/yr',\n",
       " '₹11,93,390/yr',\n",
       " '₹xx,xx,xxx/yr',\n",
       " '₹x,xx,xxx/yr',\n",
       " '₹xx,xx,xxx/yr',\n",
       " '₹xx,xx,xxx/yr',\n",
       " '₹xx,xx,xxx/yr',\n",
       " '₹x,xx,xxx/yr',\n",
       " '₹xx,xx,xxx/yr',\n",
       " '₹x,xx,xxx/yr',\n",
       " '₹xx,xx,xxx/yr',\n",
       " '₹xx,xx,xxx/yr',\n",
       " '₹xx,xx,xxx/yr',\n",
       " '₹xx,xx,xxx/yr',\n",
       " '₹xx,xx,xxx/yr',\n",
       " '₹xx,xx,xxx/yr',\n",
       " '₹xx,xxx/mo',\n",
       " '₹xx,xx,xxx/yr',\n",
       " '₹xx,xxx/mo']"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_sal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹4L',\n",
       " '₹13L',\n",
       " '₹1L',\n",
       " '₹28L',\n",
       " '₹6L',\n",
       " '₹23L',\n",
       " '₹xL',\n",
       " '₹xCr',\n",
       " '₹xL',\n",
       " '₹xxL',\n",
       " '₹xL',\n",
       " '₹xxL',\n",
       " '₹xL',\n",
       " '₹xxL',\n",
       " '₹xxL',\n",
       " '₹xxL',\n",
       " '₹xL',\n",
       " '₹xxL',\n",
       " '₹xL',\n",
       " '₹xxL',\n",
       " '₹xL',\n",
       " '₹xxL',\n",
       " '₹xL',\n",
       " '₹xxL',\n",
       " '₹xL',\n",
       " '₹xxL',\n",
       " '₹xL',\n",
       " '₹xxL',\n",
       " '₹xxL',\n",
       " '₹xxL',\n",
       " '₹xL',\n",
       " '₹xxL',\n",
       " '₹xxL',\n",
       " '₹xxL',\n",
       " '₹xxT',\n",
       " '₹xL',\n",
       " '₹xL',\n",
       " '₹xxL',\n",
       " '₹xxT',\n",
       " '₹xxT']"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separating min and max salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sal =[]\n",
    "max_sal = []\n",
    "\n",
    "for i in range(0,len(sals),2):\n",
    "    min_sal.append(sals[i])\n",
    "for j in range(1,len(sals),2):\n",
    "    max_sal.append(sals[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹4L',\n",
       " '₹1L',\n",
       " '₹6L',\n",
       " '₹xL',\n",
       " '₹xL',\n",
       " '₹xL',\n",
       " '₹xL',\n",
       " '₹xxL',\n",
       " '₹xL',\n",
       " '₹xL',\n",
       " '₹xL',\n",
       " '₹xL',\n",
       " '₹xL',\n",
       " '₹xL',\n",
       " '₹xxL',\n",
       " '₹xL',\n",
       " '₹xxL',\n",
       " '₹xxT',\n",
       " '₹xL',\n",
       " '₹xxT']"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_sal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹13L',\n",
       " '₹28L',\n",
       " '₹23L',\n",
       " '₹xCr',\n",
       " '₹xxL',\n",
       " '₹xxL',\n",
       " '₹xxL',\n",
       " '₹xxL',\n",
       " '₹xxL',\n",
       " '₹xxL',\n",
       " '₹xxL',\n",
       " '₹xxL',\n",
       " '₹xxL',\n",
       " '₹xxL',\n",
       " '₹xxL',\n",
       " '₹xxL',\n",
       " '₹xxL',\n",
       " '₹xL',\n",
       " '₹xxL',\n",
       " '₹xxT']"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Minimum Salary(₹)</th>\n",
       "      <th>Maximum Salary(₹)</th>\n",
       "      <th>Average Salary(₹)</th>\n",
       "      <th>Number of Salaries</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>₹4L</td>\n",
       "      <td>₹13L</td>\n",
       "      <td>₹6,28,021/yr</td>\n",
       "      <td>22 salaries</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>IBM</td>\n",
       "      <td>₹1L</td>\n",
       "      <td>₹28L</td>\n",
       "      <td>₹9,08,246/yr</td>\n",
       "      <td>20 salaries</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>₹6L</td>\n",
       "      <td>₹23L</td>\n",
       "      <td>₹11,93,390/yr</td>\n",
       "      <td>15 salaries</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhivery</td>\n",
       "      <td>₹xL</td>\n",
       "      <td>₹xCr</td>\n",
       "      <td>₹xx,xx,xxx/yr</td>\n",
       "      <td>15 salaries</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>₹xL</td>\n",
       "      <td>₹xxL</td>\n",
       "      <td>₹x,xx,xxx/yr</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>₹xL</td>\n",
       "      <td>₹xxL</td>\n",
       "      <td>₹xx,xx,xxx/yr</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Optum</td>\n",
       "      <td>₹xL</td>\n",
       "      <td>₹xxL</td>\n",
       "      <td>₹xx,xx,xxx/yr</td>\n",
       "      <td>11 salaries</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Optum Global Solutions</td>\n",
       "      <td>₹xxL</td>\n",
       "      <td>₹xxL</td>\n",
       "      <td>₹xx,xx,xxx/yr</td>\n",
       "      <td>10 salaries</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>₹xL</td>\n",
       "      <td>₹xxL</td>\n",
       "      <td>₹x,xx,xxx/yr</td>\n",
       "      <td>10 salaries</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>EXL Service</td>\n",
       "      <td>₹xL</td>\n",
       "      <td>₹xxL</td>\n",
       "      <td>₹xx,xx,xxx/yr</td>\n",
       "      <td>9 salaries</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Job Title                    Company Minimum Salary(₹)  \\\n",
       "1   Data Scientist  Tata Consultancy Services               ₹4L   \n",
       "2   Data Scientist                        IBM               ₹1L   \n",
       "3   Data Scientist                  Accenture               ₹6L   \n",
       "4   Data Scientist                  Delhivery               ₹xL   \n",
       "5   Data Scientist         Ericsson-Worldwide               ₹xL   \n",
       "6   Data Scientist         UnitedHealth Group               ₹xL   \n",
       "7   Data Scientist                      Optum               ₹xL   \n",
       "8   Data Scientist     Optum Global Solutions              ₹xxL   \n",
       "9   Data Scientist         Valiance Solutions               ₹xL   \n",
       "10  Data Scientist                EXL Service               ₹xL   \n",
       "\n",
       "   Maximum Salary(₹) Average Salary(₹) Number of Salaries Rating  \n",
       "1               ₹13L      ₹6,28,021/yr        22 salaries    3.9  \n",
       "2               ₹28L      ₹9,08,246/yr        20 salaries    3.9  \n",
       "3               ₹23L     ₹11,93,390/yr        15 salaries    4.1  \n",
       "4               ₹xCr     ₹xx,xx,xxx/yr        15 salaries    3.7  \n",
       "5               ₹xxL      ₹x,xx,xxx/yr        14 salaries      4  \n",
       "6               ₹xxL     ₹xx,xx,xxx/yr        14 salaries    3.7  \n",
       "7               ₹xxL     ₹xx,xx,xxx/yr        11 salaries    3.7  \n",
       "8               ₹xxL     ₹xx,xx,xxx/yr        10 salaries    3.9  \n",
       "9               ₹xxL      ₹x,xx,xxx/yr        10 salaries    4.2  \n",
       "10              ₹xxL     ₹xx,xx,xxx/yr         9 salaries    3.6  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making DataFrame\n",
    "Job_df = pd.DataFrame({\"Job Title\":job_title[0:10],\"Company\":company[0:10],\"Minimum Salary(₹)\":min_sal[0:10],\"Maximum Salary(₹)\":max_sal[0:10],\"Average Salary(₹)\":avg_sal[0:10],\"Number of Salaries\":sal_num[0:10],\"Rating\":Rating[0:10]})\n",
    "Job_df.reset_index(drop=True,inplace = True)\n",
    "Job_df.index+= 1\n",
    "Job_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount %\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to flipkart webpage by url https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon\n",
    "3. after that you will reach to a webpage having a lot of sunglasses. From this page you can scrap the required data as usual.\n",
    "4. after scraping data from the first page, go to the “Next” Button at the bottom of the page , then click on it\n",
    "5. Now scrape data from this page as usual\n",
    "6. repeat this until you get data for 100 sunglasses.\n",
    "Note that all of the above steps have to be done by coding only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Sourabh\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.flipkart.com' \n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "glassessearch = driver.find_element_by_xpath('//input[@class=\"_3704LK\"]')\n",
    "glassessearch.send_keys(\"Sunglasses\")\n",
    "search = driver.find_element_by_class_name('L0Z3Pu')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand = []\n",
    "desc = []\n",
    "price = []\n",
    "disc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_tag = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "price_tag = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "disc_tag = driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']//span\")\n",
    "desc_tag = driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "\n",
    "for b in brand_tag:\n",
    "    brand.append(b.text)\n",
    "for d in desc_tag :\n",
    "    desc.append(d.text)\n",
    "for p in price_tag:\n",
    "    price.append(p.text)\n",
    "for c in disc_tag:\n",
    "    disc.append(c.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "nextbtn = driver.find_element_by_class_name('_1LKTO3')\n",
    "while(i<2):\n",
    "    try:\n",
    "        nextbtn.click()\n",
    "    except:\n",
    "        pass\n",
    "    time.sleep(3) #to allow the page to load completely before scraping.\n",
    "    brand_tag = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    price_tag = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    disc_tag = driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']//span\")\n",
    "    desc_tag = driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "    \n",
    "    for b in brand_tag:\n",
    "        try:\n",
    "            brand.append(b.text)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    for d in desc_tag :\n",
    "        try:\n",
    "            desc.append(d.text)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    for p in price_tag:\n",
    "        try:\n",
    "            price.append(p.text)\n",
    "        except:\n",
    "            pass\n",
    "    for c in disc_tag:\n",
    "        try:\n",
    "            disc.append(c.text)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    \n",
    "    if 'inactive' in nextbtn.get_attribute('class'):\n",
    "        break;\n",
    "    \n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making the DataFrame \n",
    "#Sunglasses_df DataFrame\n",
    "Sunglasses_df = pd.DataFrame({\"Brand Name\":brand[0:100],\"Price(₹)\":price[0:100],\"Discount\":disc[0:100],\"Description\":desc[0:100],})\n",
    "Sunglasses_df.reset_index(drop=True,inplace = True)\n",
    "Sunglasses_df.index+= 1\n",
    "Sunglasses_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price(₹)</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>₹525</td>\n",
       "      <td>65% off</td>\n",
       "      <td>UV Protection, Gradient Wayfarer, Clubmaster S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>₹331</td>\n",
       "      <td>83% off</td>\n",
       "      <td>Mirrored, UV Protection, Riding Glasses, Other...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>₹295</td>\n",
       "      <td>88% off</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SHAAH COLLECTIONS</td>\n",
       "      <td>₹198</td>\n",
       "      <td>88% off</td>\n",
       "      <td>UV Protection, Polarized, Mirrored Rectangular...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>₹284</td>\n",
       "      <td>89% off</td>\n",
       "      <td>Mirrored, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>₹425</td>\n",
       "      <td>70% off</td>\n",
       "      <td>UV Protection Cat-eye Sunglasses (60)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>₹449</td>\n",
       "      <td>77% off</td>\n",
       "      <td>UV Protection, Gradient Retro Square Sunglasse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>hipe</td>\n",
       "      <td>₹319</td>\n",
       "      <td>83% off</td>\n",
       "      <td>UV Protection Sports Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>₹499</td>\n",
       "      <td>72% off</td>\n",
       "      <td>UV Protection Round Sunglasses (47)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>₹365</td>\n",
       "      <td>68% off</td>\n",
       "      <td>UV Protection, Gradient, Night Vision, Mirrore...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Brand Name Price(₹) Discount  \\\n",
       "1               AISLIN     ₹525  65% off   \n",
       "2         Singco India     ₹331  83% off   \n",
       "3            Elligator     ₹295  88% off   \n",
       "4    SHAAH COLLECTIONS     ₹198  88% off   \n",
       "5       kingsunglasses     ₹284  89% off   \n",
       "..                 ...      ...      ...   \n",
       "96               NuVew     ₹425  70% off   \n",
       "97      ROZZETTA CRAFT     ₹449  77% off   \n",
       "98                hipe     ₹319  83% off   \n",
       "99           ROYAL SON     ₹499  72% off   \n",
       "100              NuVew     ₹365  68% off   \n",
       "\n",
       "                                           Description  \n",
       "1    UV Protection, Gradient Wayfarer, Clubmaster S...  \n",
       "2    Mirrored, UV Protection, Riding Glasses, Other...  \n",
       "3                  UV Protection Round Sunglasses (54)  \n",
       "4    UV Protection, Polarized, Mirrored Rectangular...  \n",
       "5    Mirrored, UV Protection Wayfarer Sunglasses (F...  \n",
       "..                                                 ...  \n",
       "96               UV Protection Cat-eye Sunglasses (60)  \n",
       "97   UV Protection, Gradient Retro Square Sunglasse...  \n",
       "98         UV Protection Sports Sunglasses (Free Size)  \n",
       "99                 UV Protection Round Sunglasses (47)  \n",
       "100  UV Protection, Gradient, Night Vision, Mirrore...  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sunglasses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link:\n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace.\n",
    "When you will open the above link you will reach to the below shown webpage.\n",
    "As shown in the above page you have to scrape the tick marked attributes.\n",
    "These are\n",
    "1. Rating\n",
    "2. Review_summary\n",
    "3. Full review\n",
    "You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Sourabh\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace' \n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewall = driver.find_element_by_xpath('//div[@class=\"_3UAT2v _16PBlm\"]')\n",
    "viewall.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_sum = []\n",
    "rating = []\n",
    "rev = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_sum_tag = driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "rating_tag = driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "rev_tag = driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "    \n",
    "\n",
    "for r in rev_sum_tag:\n",
    "    rev_sum.append(r.text)\n",
    "for j in rating_tag :\n",
    "    rating.append(j.text)\n",
    "for k in rev_tag:\n",
    "    rev.append(k.text.replace(\"\\n\",\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#By try and except method\n",
    "\n",
    "i=0\n",
    "nextbtn = driver.find_element_by_class_name('_1LKTO3')\n",
    "while(i<10):\n",
    "    try:\n",
    "        nextbtn.click()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    time.sleep(3) #to allow the page to load completely before scraping.\n",
    "    rev_sum_tag = driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "    rating_tag = driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "    rev_tag = driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "    for r in rev_sum_tag:\n",
    "        try:\n",
    "            rev_sum.append(r.text)\n",
    "        except:\n",
    "            pass\n",
    "    for j in rating_tag :\n",
    "        try:\n",
    "            rating.append(j.text)\n",
    "        except:\n",
    "            pass\n",
    "    for k in rev_tag:\n",
    "        try:\n",
    "            rev.append(k.text.replace(\"\\n\",\" \"))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making DataFrame for iphone 11\n",
    "\n",
    "iphone11_df = pd.DataFrame({\"Summary\":rev_sum[0:100],\"Full Review\":rev[0:100],\"Rating\":rating[0:100]})\n",
    "iphone11_df.reset_index(drop=True,inplace = True)\n",
    "iphone11_df.index+= 1\n",
    "iphone11_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>Full Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money  The iPhone 11 of...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Best budget Iphone till date ❤️ go for it guys...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Iphone is just awesome.. battery backup is ver...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Excellent camera, good performance, no lag. Th...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>It’s been almost a month since I have been usi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Terrific</td>\n",
       "      <td>Really worth of money. i just love it. It is t...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Summary                                        Full Review  \\\n",
       "1              Brilliant  The Best Phone for the Money  The iPhone 11 of...   \n",
       "2         Simply awesome  Really satisfied with the Product I received.....   \n",
       "3    Best in the market!  Great iPhone very snappy experience as apple k...   \n",
       "4       Perfect product!  Amazing phone with great cameras and better ba...   \n",
       "5              Fabulous!  This is my first iOS phone. I am very happy wi...   \n",
       "..                   ...                                                ...   \n",
       "96     Worth every penny  Best budget Iphone till date ❤️ go for it guys...   \n",
       "97      Perfect product!  Iphone is just awesome.. battery backup is ver...   \n",
       "98        Simply awesome  Excellent camera, good performance, no lag. Th...   \n",
       "99     Worth every penny  It’s been almost a month since I have been usi...   \n",
       "100             Terrific  Really worth of money. i just love it. It is t...   \n",
       "\n",
       "    Rating  \n",
       "1        5  \n",
       "2        5  \n",
       "3        5  \n",
       "4        5  \n",
       "5        5  \n",
       "..     ...  \n",
       "96       5  \n",
       "97       5  \n",
       "98       5  \n",
       "99       5  \n",
       "100      5  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iphone11_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %\n",
    "As shown in the below image, you have to scrape the tick marked attributes.\n",
    "Also note that all the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Sourabh\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.flipkart.com' \n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sneakerssearch = driver.find_element_by_xpath('//input[@class=\"_3704LK\"]')\n",
    "Sneakerssearch.send_keys(\"Sneakers\")\n",
    "search = driver.find_element_by_class_name('L0Z3Pu')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand = []\n",
    "desc = []\n",
    "price = []\n",
    "disc = []\n",
    "brand_tag = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "price_tag = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "disc_tag = driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']//span\")\n",
    "desc_tag = driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "for b in brand_tag:\n",
    "    brand.append(b.text)\n",
    "for d in desc_tag :\n",
    "    desc.append(d.text)\n",
    "for p in price_tag:\n",
    "    price.append(p.text)\n",
    "for c in disc_tag:\n",
    "    disc.append(c.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing time\n",
    "import time \n",
    "\n",
    "#By try and exception method\n",
    "i=0\n",
    "nextbtn = driver.find_element_by_class_name('_1LKTO3')\n",
    "while(i<2):\n",
    "    try:\n",
    "        nextbtn.click()\n",
    "    except:\n",
    "        pass\n",
    "    time.sleep(3) #to allow the page to load completely before scraping.\n",
    "    brand_tag = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    price_tag = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    disc_tag = driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']//span\")\n",
    "    desc_tag = driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "    \n",
    "    for b in brand_tag:\n",
    "        try:\n",
    "            brand.append(b.text)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    for d in desc_tag :\n",
    "        try:\n",
    "            desc.append(d.text)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    for p in price_tag:\n",
    "        try:\n",
    "            price.append(p.text)\n",
    "        except:\n",
    "            pass\n",
    "    for c in disc_tag:\n",
    "        try:\n",
    "            disc.append(c.text)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    \n",
    "    if 'inactive' in nextbtn.get_attribute('class'):\n",
    "        break;\n",
    "    \n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making DataFrame as Sneakers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price(₹)</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>₹356</td>\n",
       "      <td>64% off</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>₹474</td>\n",
       "      <td>86% off</td>\n",
       "      <td>Combo Pack Of 4 Casual Shoes Loafer Shoes Snea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Longwalk</td>\n",
       "      <td>₹236</td>\n",
       "      <td>52% off</td>\n",
       "      <td>Men Boxer Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASTEROID</td>\n",
       "      <td>₹499</td>\n",
       "      <td>75% off</td>\n",
       "      <td>Original Luxury Branded Fashionable Men's Casu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>₹599</td>\n",
       "      <td>66% off</td>\n",
       "      <td>Perfect &amp; Affordable Combo Pack of 02 Pairs Sn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>₹359</td>\n",
       "      <td>28% off</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>SHOEFLY</td>\n",
       "      <td>₹362</td>\n",
       "      <td>70% off</td>\n",
       "      <td>Combo pack of 2 casual sneaker shoes for men S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>HOC</td>\n",
       "      <td>₹398</td>\n",
       "      <td>80% off</td>\n",
       "      <td>Respin SL Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Zsyto</td>\n",
       "      <td>₹398</td>\n",
       "      <td>69% off</td>\n",
       "      <td>Casual , Partywear Sneakers Shoes For Men's An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>₹215</td>\n",
       "      <td>64% off</td>\n",
       "      <td>White Sneaker For Men's/Boy's Sneakers For Men</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Brand Name Price(₹) Discount  \\\n",
       "1     Magnolia     ₹356  64% off   \n",
       "2       BRUTON     ₹474  86% off   \n",
       "3     Longwalk     ₹236  52% off   \n",
       "4     ASTEROID     ₹499  75% off   \n",
       "5       Chevit     ₹599  66% off   \n",
       "..         ...      ...      ...   \n",
       "96       BIRDE     ₹359  28% off   \n",
       "97     SHOEFLY     ₹362  70% off   \n",
       "98         HOC     ₹398  80% off   \n",
       "99       Zsyto     ₹398  69% off   \n",
       "100     BRUTON     ₹215  64% off   \n",
       "\n",
       "                                           Description  \n",
       "1                                     Sneakers For Men  \n",
       "2    Combo Pack Of 4 Casual Shoes Loafer Shoes Snea...  \n",
       "3                           Men Boxer Sneakers For Men  \n",
       "4    Original Luxury Branded Fashionable Men's Casu...  \n",
       "5    Perfect & Affordable Combo Pack of 02 Pairs Sn...  \n",
       "..                                                 ...  \n",
       "96                                    Sneakers For Men  \n",
       "97   Combo pack of 2 casual sneaker shoes for men S...  \n",
       "98                          Respin SL Sneakers For Men  \n",
       "99   Casual , Partywear Sneakers Shoes For Men's An...  \n",
       "100     White Sneaker For Men's/Boy's Sneakers For Men  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sneakers_df = pd.DataFrame({\"Brand Name\":brand[0:100],\"Price(₹)\":price[0:100],\"Discount\":disc[0:100],\"Description\":desc[0:100],})\n",
    "Sneakers_df.reset_index(drop=True,inplace = True)\n",
    "Sneakers_df.index+= 1\n",
    "Sneakers_df.shape\n",
    "\n",
    "Sneakers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q9: Go to the link - \n",
    "https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”, as shown in the below image\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe as shown in the below image.\n",
    "Please note that applying the filter and scraping the data , everything should be done through code only and there should not be any manual step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Sourabh\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.myntra.com/shoes' \n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "colour_filter = driver.find_element_by_xpath(\"//li[@class='colour-listItem']\")\n",
    "colour_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_filter = driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label\")\n",
    "price_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand = []\n",
    "desc = []\n",
    "price = []\n",
    "price2 = []\n",
    "brand_tag = driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")\n",
    "price_tag = driver.find_elements_by_xpath(\"//div[@class='product-price']//span[1]\")\n",
    "desc_tag = driver.find_elements_by_xpath(\"//h4[@class='product-product']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in brand_tag:\n",
    "    brand.append(b.text)\n",
    "for d in desc_tag :\n",
    "    desc.append(d.text)\n",
    "for p in price_tag:\n",
    "    price.append(p.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "#by try and exception method\n",
    "\n",
    "i=0\n",
    "nextbtn = driver.find_element_by_class_name('pagination-next')\n",
    "while(i<1):\n",
    "    try:\n",
    "        nextbtn.click()\n",
    "    except:\n",
    "        pass\n",
    "    time.sleep(3) #to allow the page to load completely before scraping.\n",
    "    brand_tag = driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")\n",
    "    price_tag = driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']//span[1]\")\n",
    "    desc_tag = driver.find_elements_by_xpath(\"//h4[@class='product-product']\")\n",
    "\n",
    "    \n",
    "    for b in brand_tag:\n",
    "        try:\n",
    "            brand.append(b.text)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    for d in desc_tag :\n",
    "        try:\n",
    "            desc.append(d.text)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    for p in price_tag:\n",
    "        try:\n",
    "            price.append(p.text)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    \n",
    "    if 'inactive' in nextbtn.get_attribute('class'):\n",
    "        break;\n",
    "    \n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rs. 6999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 8099Rs. 8999',\n",
       " 'Rs. 8099',\n",
       " 'Rs. 10499Rs. 14999',\n",
       " 'Rs. 10499',\n",
       " 'Rs. 8999Rs. 9999',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 7499',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 7499Rs. 9999',\n",
       " 'Rs. 7499',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 10999',\n",
       " 'Rs. 11999',\n",
       " 'Rs. 13599Rs. 16999',\n",
       " 'Rs. 13599',\n",
       " 'Rs. 10999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 8599',\n",
       " 'Rs. 6999Rs. 9999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 7799Rs. 12999',\n",
       " 'Rs. 7799',\n",
       " 'Rs. 12999',\n",
       " 'Rs. 7195',\n",
       " 'Rs. 7599',\n",
       " 'Rs. 10999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 8490',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 7199Rs. 8999',\n",
       " 'Rs. 7199',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 11199Rs. 13999',\n",
       " 'Rs. 11199',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 8990',\n",
       " 'Rs. 8999Rs. 9999',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 10999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 7149Rs. 10999',\n",
       " 'Rs. 7149',\n",
       " 'Rs. 6999Rs. 9999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 8999Rs. 9999',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 7499',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 11999',\n",
       " '',\n",
       " 'Rs. 6999',\n",
       " '',\n",
       " 'Rs. 6999',\n",
       " '',\n",
       " 'Rs. 8099Rs. 8999',\n",
       " 'Rs. 8099',\n",
       " '',\n",
       " 'Rs. 10499Rs. 14999',\n",
       " 'Rs. 10499',\n",
       " '',\n",
       " 'Rs. 8999Rs. 9999',\n",
       " 'Rs. 8999',\n",
       " '',\n",
       " 'Rs. 6999',\n",
       " '',\n",
       " 'Rs. 7499',\n",
       " '',\n",
       " 'Rs. 6999',\n",
       " '',\n",
       " 'Rs. 7499Rs. 9999',\n",
       " 'Rs. 7499',\n",
       " '',\n",
       " 'Rs. 7999',\n",
       " '',\n",
       " 'Rs. 10999',\n",
       " '',\n",
       " 'Rs. 11999',\n",
       " '',\n",
       " 'Rs. 13599Rs. 16999',\n",
       " 'Rs. 13599',\n",
       " '',\n",
       " 'Rs. 10999',\n",
       " '',\n",
       " 'Rs. 6999',\n",
       " '',\n",
       " 'Rs. 8599',\n",
       " '',\n",
       " 'Rs. 6999Rs. 9999',\n",
       " 'Rs. 6999',\n",
       " '',\n",
       " 'Rs. 7799Rs. 12999',\n",
       " 'Rs. 7799',\n",
       " '',\n",
       " 'Rs. 12999',\n",
       " '',\n",
       " 'Rs. 7195',\n",
       " '',\n",
       " 'Rs. 7599',\n",
       " '',\n",
       " 'Rs. 10999',\n",
       " '',\n",
       " 'Rs. 6999',\n",
       " '',\n",
       " 'Rs. 7999',\n",
       " '',\n",
       " 'Rs. 8490',\n",
       " '',\n",
       " 'Rs. 9999',\n",
       " '',\n",
       " 'Rs. 7199Rs. 8999',\n",
       " 'Rs. 7199',\n",
       " '',\n",
       " 'Rs. 6999',\n",
       " '',\n",
       " 'Rs. 11199Rs. 13999',\n",
       " 'Rs. 11199',\n",
       " '',\n",
       " 'Rs. 9999',\n",
       " '',\n",
       " 'Rs. 9999',\n",
       " '',\n",
       " 'Rs. 9999',\n",
       " '',\n",
       " 'Rs. 8990',\n",
       " '',\n",
       " 'Rs. 8999Rs. 9999',\n",
       " 'Rs. 8999',\n",
       " '',\n",
       " 'Rs. 10999',\n",
       " '',\n",
       " 'Rs. 7999',\n",
       " '',\n",
       " 'Rs. 7149Rs. 10999',\n",
       " 'Rs. 7149',\n",
       " '',\n",
       " 'Rs. 6999Rs. 9999',\n",
       " 'Rs. 6999',\n",
       " '',\n",
       " 'Rs. 8999',\n",
       " '',\n",
       " 'Rs. 8999',\n",
       " '',\n",
       " 'Rs. 7999',\n",
       " '',\n",
       " 'Rs. 9999',\n",
       " '',\n",
       " 'Rs. 8999Rs. 9999',\n",
       " 'Rs. 8999',\n",
       " '',\n",
       " 'Rs. 9999',\n",
       " '',\n",
       " 'Rs. 6999',\n",
       " '',\n",
       " 'Rs. 7499',\n",
       " '',\n",
       " 'Rs. 8999',\n",
       " '',\n",
       " 'Rs. 9999',\n",
       " 'UK4,',\n",
       " 'Rs. 9999',\n",
       " '',\n",
       " 'Rs. 11999']"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price\n",
    "#has duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(\"\" in price) :\n",
    "    price.remove(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing duplicate values\n",
    "j = 0\n",
    "for c in price:\n",
    "    if len(c) > 12:\n",
    "        del price[j]\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rs. 6999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 8099',\n",
       " 'Rs. 10499',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 7499',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 7499',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 10999',\n",
       " 'Rs. 11999',\n",
       " 'Rs. 13599',\n",
       " 'Rs. 10999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 8599',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 7799',\n",
       " 'Rs. 12999',\n",
       " 'Rs. 7195',\n",
       " 'Rs. 7599',\n",
       " 'Rs. 10999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 8490',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 7199',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 11199',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 8990',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 10999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 7149',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 7499',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 11999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 8099',\n",
       " 'Rs. 10499',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 7499',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 7499',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 10999',\n",
       " 'Rs. 11999',\n",
       " 'Rs. 13599',\n",
       " 'Rs. 10999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 8599',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 7799',\n",
       " 'Rs. 12999',\n",
       " 'Rs. 7195',\n",
       " 'Rs. 7599',\n",
       " 'Rs. 10999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 8490',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 7199',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 11199',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 8990',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 10999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 7149',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 6999',\n",
       " 'Rs. 7499',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 9999',\n",
       " 'UK4,',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 11999']"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAking DataFrame\n",
    "\n",
    "MyntraShoes_df = pd.DataFrame({\"Brand Name\":brand[0:100],\"Price(₹)\":price[0:100],\"Description\":desc[0:100],})\n",
    "MyntraShoes_df.reset_index(drop=True,inplace = True)\n",
    "MyntraShoes_df.index+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price(₹)</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Rs. 6999</td>\n",
       "      <td>Men BlackTraining or Gym Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Rs. 6999</td>\n",
       "      <td>Men Cell Fraction Fade Running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Rs. 8099</td>\n",
       "      <td>Men Solid Leather Formal Slip-Ons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Rs. 10499</td>\n",
       "      <td>Women Deviate Nitro Running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Rs. 8999</td>\n",
       "      <td>Men Solid Leather Formal Slip-Ons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Rs. 7499</td>\n",
       "      <td>Women Provoke XT FTR Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Rs. 8999</td>\n",
       "      <td>Women Charged Bandit 6 Running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Rs. 9999</td>\n",
       "      <td>Men Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Puma</td>\n",
       "      <td>UK4,</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>ROSSO BRUNELLO</td>\n",
       "      <td>Rs. 9999</td>\n",
       "      <td>Men Leather Formal Loafers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Brand Name   Price(₹)                        Description\n",
       "1              Puma   Rs. 6999     Men BlackTraining or Gym Shoes\n",
       "2              Puma   Rs. 6999     Men Cell Fraction Fade Running\n",
       "3      Hush Puppies   Rs. 8099  Men Solid Leather Formal Slip-Ons\n",
       "4              Puma  Rs. 10499        Women Deviate Nitro Running\n",
       "5      Hush Puppies   Rs. 8999  Men Solid Leather Formal Slip-Ons\n",
       "..              ...        ...                                ...\n",
       "96             Puma   Rs. 7499         Women Provoke XT FTR Shoes\n",
       "97     UNDER ARMOUR   Rs. 8999     Women Charged Bandit 6 Running\n",
       "98             Geox   Rs. 9999                       Men Sneakers\n",
       "99             Puma       UK4,                                   \n",
       "100  ROSSO BRUNELLO   Rs. 9999         Men Leather Formal Loafers\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyntraShoes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q10: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9”\n",
    "attributes for each laptop:\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Sourabh\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.amazon.in/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to write laptop in the search box \n",
    "Laptopsearch = driver.find_element_by_xpath('//input[@id=\"twotabsearchtextbox\"]') \n",
    "Laptopsearch.send_keys (\"Laptop\")\n",
    "# code to click on the search button \n",
    "search_btn = driver.find_element_by_xpath('//input[@id=\"nav-search-submit-button\"]') \n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the core i7 filter\n",
    "filter_button=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "\n",
    "for i in filter_button: \n",
    "    if i.text=='Intel Core i7': \n",
    "        i.click()\n",
    "        break\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "\n",
    "for a in filter:\n",
    "    if a.text == \"Intel Core 19\":\n",
    "        a.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls4 = []\n",
    "\n",
    "for b in driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\"): \n",
    "    urls4.append(b.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the empty list\n",
    "Title=[]\n",
    "Ratings=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in urls4:\n",
    "    driver.get(i)\n",
    "time.sleep (5)\n",
    "'''\n",
    "try:\n",
    "    title10 =driver.find_element_by_xpath(\"//span[@class='a-size-large product-title-word-break']\") \n",
    "    Title10.append(title10.text)\n",
    "except:\n",
    "    Title10.append(\"--\")\n",
    "'''\n",
    "try:\n",
    "    rate10= driver.find_element_by_xpath(\"//span[@class='a-size-base a-nowrap']\")\n",
    "    Ratings10.append(rate10.text)\n",
    "\n",
    "except:\n",
    "    Ratings10.append(\"--\")\n",
    "\n",
    "try:\n",
    "    price10 =driver.find_element_by_xpath(\"//span[@class='a-size-medium a-color-price priceBlockBuying PriceString']\") \n",
    "    Price10.append(price10.text)\n",
    "\n",
    "except:\n",
    "    Price10.append(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in urls4:\n",
    "    driver.get(i)\n",
    "\n",
    "time.sleep (5)\n",
    "\n",
    "title10=driver.find_element_by_xpath(\"//span[@class='a-size-large product-title-word-break']\") \n",
    "Title10.append(title10.text)\n",
    "\n",
    "print(Title10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Ratings10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(price10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amazon = pd.DataFrame({})\n",
    "df_amazon[\"Title\"]= Title10\n",
    "df_amazon[\"Ratings\"]=Ratings10\n",
    "df_amazon[\"Price\"]= Price10\n",
    "df amazon"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
